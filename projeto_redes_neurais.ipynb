{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting optuna\n",
      "  Downloading optuna-3.0.2-py3-none-any.whl (348 kB)\n",
      "\u001b[K     |████████████████████████████████| 348 kB 384 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from optuna) (20.3)\n",
      "Requirement already satisfied: numpy in /home/luizkof/.local/lib/python3.8/site-packages (from optuna) (1.19.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/luizkof/.local/lib/python3.8/site-packages (from optuna) (1.4.41)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna) (5.3.1)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 5.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/luizkof/.local/lib/python3.8/site-packages (from optuna) (1.8.1)\n",
      "Collecting cliff\n",
      "  Downloading cliff-4.0.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy<1.9.0,>=1.7.0\n",
      "  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 41.6 MB 10.0 MB/s eta 0:00:01     |█████████████▋                  | 17.7 MB 12.7 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /home/luizkof/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (4.12.0)\n",
      "Requirement already satisfied: importlib-resources in /home/luizkof/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (5.9.0)\n",
      "Requirement already satisfied: Mako in /home/luizkof/.local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/luizkof/.local/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Downloading stevedore-4.0.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 3.4 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-3.4.1-py3-none-any.whl (26 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /home/luizkof/.local/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /usr/lib/python3/dist-packages (from cmd2>=1.0.0->cliff->optuna) (19.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/luizkof/.local/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.10.0-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 77 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /home/luizkof/.local/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=5b9802bafd6ad2d1c2fda829fce62f18e661516a815c54d8fb91c291da603db9\n",
      "  Stored in directory: /home/luizkof/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyperclip, pbr, stevedore, PrettyTable, cmd2, autopage, tqdm, scipy, colorlog, cmaes, cliff, optuna\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.4\n",
      "    Uninstalling scipy-1.5.4:\n",
      "      Successfully uninstalled scipy-1.5.4\n",
      "Successfully installed PrettyTable-3.4.1 autopage-0.5.1 cliff-4.0.0 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.2 pbr-5.10.0 pyperclip-1.8.2 scipy-1.8.1 stevedore-4.0.0 tqdm-4.64.1\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mlflow in /home/luizkof/.local/lib/python3.8/site-packages (1.29.0)\n",
      "Requirement already satisfied: scikit-learn in /home/luizkof/.local/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (3.1.27)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /usr/lib/python3/dist-packages (from mlflow) (4.1.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/lib/python3/dist-packages (from mlflow) (5.3.1)\n",
      "Requirement already satisfied: pandas<2 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (1.1.4)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/lib/python3/dist-packages (from mlflow) (7.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (4.21.6)\n",
      "Requirement already satisfied: scipy<2 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (1.8.1)\n",
      "Requirement already satisfied: gunicorn<21 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: prometheus-flask-exporter<1 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (0.20.3)\n",
      "Requirement already satisfied: querystring-parser<2 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: Flask<3 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (0.10.1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/lib/python3/dist-packages (from mlflow) (2.22.0)\n",
      "Requirement already satisfied: pytz<2023 in /usr/lib/python3/dist-packages (from mlflow) (2019.3)\n",
      "Requirement already satisfied: entrypoints<1 in /usr/lib/python3/dist-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: numpy<2 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (1.19.2)\n",
      "Requirement already satisfied: packaging<22 in /usr/lib/python3/dist-packages (from mlflow) (20.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (0.4.3)\n",
      "Requirement already satisfied: cloudpickle<3 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (2.2.0)\n",
      "Requirement already satisfied: alembic<2 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (1.8.1)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (0.17.3)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<5,>=3.7.0 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (4.12.0)\n",
      "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /home/luizkof/.local/lib/python3.8/site-packages (from mlflow) (1.4.41)\n",
      "Requirement already satisfied: importlib-resources in /home/luizkof/.local/lib/python3.8/site-packages (from alembic<2->mlflow) (5.9.0)\n",
      "Requirement already satisfied: Mako in /home/luizkof/.local/lib/python3.8/site-packages (from alembic<2->mlflow) (1.2.3)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.1.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/luizkof/.local/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.14.0)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in /home/luizkof/.local/lib/python3.8/site-packages (from Flask<3->mlflow) (2.1.2)\n",
      "Requirement already satisfied: Jinja2>=2.4 in /home/luizkof/.local/lib/python3.8/site-packages (from Flask<3->mlflow) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.21 in /home/luizkof/.local/lib/python3.8/site-packages (from Flask<3->mlflow) (2.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/luizkof/.local/lib/python3.8/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/luizkof/.local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/lib/python3/dist-packages (from gunicorn<21->mlflow) (45.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/luizkof/.local/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,<5,>=3.7.0->mlflow) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/luizkof/.local/lib/python3.8/site-packages (from Jinja2>=2.4->Flask<3->mlflow) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/luizkof/.local/lib/python3.8/site-packages (from pandas<2->mlflow) (2.8.2)\n",
      "Requirement already satisfied: prometheus-client in /home/luizkof/.local/lib/python3.8/site-packages (from prometheus-flask-exporter<1->mlflow) (0.14.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/luizkof/.local/lib/python3.8/site-packages (from sqlalchemy<2,>=1.4.0->mlflow) (1.1.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/luizkof/.local/lib/python3.8/site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/luizkof/.local/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow --quiet\n",
    "%pip install optuna\n",
    "%pip install mlflow scikit-learn\n",
    "%pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import gc\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9QOb3wEDGFy"
   },
   "source": [
    "#### Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3YBq-Nu4KfNo"
   },
   "outputs": [],
   "source": [
    "data_path = './TRNcod.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mTti3fRBrMx5"
   },
   "outputs": [],
   "source": [
    "df_excel = pd.read_csv(data_path, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpMD8CIxubmc",
    "outputId": "2649b4cf-3a24-4bc9-f770-339eba7c1c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de entradas: 389196\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de entradas:', len(df_excel.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "34DWy_XWrl4W",
    "outputId": "1b8a7a61-84ce-44ea-b449-885b664484a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX  UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  ...  \\\n",
       "0      0     1     1     1     0     0     0     0  0.135098       1  ...   \n",
       "1      1     1     0     1     0     0     1     0  0.273504       1  ...   \n",
       "2      2     1     0     1     0     0     1     0  0.281910       0  ...   \n",
       "3      3     1     1     1     0     0     0     0  0.225741       0  ...   \n",
       "4      4     1     1     0     0     0     1     0  0.480403       0  ...   \n",
       "\n",
       "   CEP4_7  CEP4_8  CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  CEP4_14  \\\n",
       "0       0       0       1        1        0        1        1        1   \n",
       "1       0       1       0        1        1        0        0        0   \n",
       "2       1       1       0        0        0        0        1        0   \n",
       "3       1       1       0        1        1        0        1        0   \n",
       "4       1       1       1        0        0        1        0        1   \n",
       "\n",
       "   IND_BOM_1_1  IND_BOM_1_2  \n",
       "0            0            1  \n",
       "1            1            0  \n",
       "2            1            0  \n",
       "3            1            0  \n",
       "4            1            0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.drop(['INDEX'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "147wgrxQ_eCX"
   },
   "source": [
    "#### Combinando classes em uma única coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Pn9epHSQuxrG"
   },
   "outputs": [],
   "source": [
    "def label_class (row):\n",
    "   if row['IND_BOM_1_1'] == 1 and row['IND_BOM_1_2'] == 1:\n",
    "      return 2\n",
    "   if row['IND_BOM_1_1'] == 1:\n",
    "      return 0\n",
    "   if row['IND_BOM_1_2'] == 1:\n",
    "      return 1\n",
    "   return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_yoSjoMX4W57"
   },
   "outputs": [],
   "source": [
    "df['class'] = df.apply (lambda row: label_class(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "dNlLOAJJ4bYk",
    "outputId": "a3585d0e-ed05-4955-d690-537bacb7f179"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0     1     1     1     0     0     0     0  0.135098       1   \n",
       "1     1     0     1     0     0     1     0  0.273504       1   \n",
       "2     1     0     1     0     0     1     0  0.281910       0   \n",
       "3     1     1     1     0     0     0     0  0.225741       0   \n",
       "4     1     1     0     0     0     1     0  0.480403       0   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "0                        0.222222  ...       0       1        1        0   \n",
       "1                        0.111111  ...       1       0        1        1   \n",
       "2                        1.000000  ...       1       0        0        0   \n",
       "3                        0.111111  ...       1       0        1        1   \n",
       "4                        0.111111  ...       1       1        0        0   \n",
       "\n",
       "   CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  class  \n",
       "0        1        1        1            0            1      1  \n",
       "1        0        0        0            1            0      0  \n",
       "2        0        1        0            1            0      0  \n",
       "3        0        1        0            1            0      0  \n",
       "4        1        0        1            1            0      0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4R6NcieU4fVQ",
    "outputId": "dda4136c-2c6f-47e2-a590-40507fc0916a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe 0: 255098\n",
      "classe 1: 134098\n",
      "classe desconhecida: 0\n"
     ]
    }
   ],
   "source": [
    "print('classe 0:', len(df[df['class'] == 0]))\n",
    "print('classe 1:', len(df[df['class'] == 1]))\n",
    "print('classe desconhecida:', len(df[df['class'] > 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Etapa - Particionamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_class_0 = df[df['class'] == 0]\n",
    "x_class_1 = df[df['class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219323</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "1     1     0     1     0     0     1     0  0.273504       1   \n",
       "2     1     0     1     0     0     1     0  0.281910       0   \n",
       "3     1     1     1     0     0     0     0  0.225741       0   \n",
       "4     1     1     0     0     0     1     0  0.480403       0   \n",
       "5     0     1     1     0     0     0     1  0.219323       0   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "1                        0.111111  ...       1       0        1        1   \n",
       "2                        1.000000  ...       1       0        0        0   \n",
       "3                        0.111111  ...       1       0        1        1   \n",
       "4                        0.111111  ...       1       1        0        0   \n",
       "5                        0.111111  ...       1       1        0        1   \n",
       "\n",
       "   CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  class  \n",
       "1        0        0        0            1            0      0  \n",
       "2        0        1        0            1            0      0  \n",
       "3        0        1        0            1            0      0  \n",
       "4        1        0        1            1            0      0  \n",
       "5        0        0        1            1            0      0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_class_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654703</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398961</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0      1     1     1     0     0     0     0  0.135098       1   \n",
       "10     1     0     1     1     0     0     0  0.654703       0   \n",
       "11     1     1     1     0     0     0     0  0.097444       1   \n",
       "12     1     0     1     0     1     0     0  0.398961       0   \n",
       "17     1     1     1     0     0     0     0  0.142254       0   \n",
       "\n",
       "    NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "0                         0.222222  ...       0       1        1        0   \n",
       "10                        0.111111  ...       1       0        1        0   \n",
       "11                        0.111111  ...       1       0        1        0   \n",
       "12                        0.111111  ...       1       1        0        1   \n",
       "17                        0.111111  ...       0       0        1        0   \n",
       "\n",
       "    CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  class  \n",
       "0         1        1        1            0            1      1  \n",
       "10        0        0        0            0            1      1  \n",
       "11        1        0        1            0            1      1  \n",
       "12        0        0        0            0            1      1  \n",
       "17        1        0        1            0            1      1  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_class_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q5lQRWw_lr9"
   },
   "source": [
    "#### 2 Etapa - Particionamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3NInOmMP70vA"
   },
   "outputs": [],
   "source": [
    "y_class_0 = x_class_0['class'].values\n",
    "y_class_1 = x_class_1['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20hYd4oJCLNG"
   },
   "source": [
    "#### Separar dados em treino, validação e treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiKN6mFZCs21"
   },
   "source": [
    "Os dados foram divididos aleatoriamente usando o método train_test_split()\n",
    "- 50% dos dados para treinamento\n",
    "- Dos 50% restantes, metade(25% do total) pra validação e o restante(25%) para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class_0, X_rem_class_0, y_train_class_0, y_rem_class_0 = train_test_split(x_class_0, y_class_0, train_size=0.5)\n",
    "X_valid_class_0, X_test_class_0, y_valid_class_0, y_test_class_0 = train_test_split(X_rem_class_0, y_rem_class_0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class_1, X_rem_class_1, y_train_class_1, y_rem_class_1 = train_test_split(x_class_1, y_class_1, train_size=0.5)\n",
    "X_valid_class_1, X_test_class_1, y_valid_class_1, y_test_class_1 = train_test_split(X_rem_class_1, y_rem_class_1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_class_0, X_train_class_1])\n",
    "y_train = np.concatenate((y_train_class_0, y_train_class_1))\n",
    "X_train = X_train.drop(['class', 'IND_BOM_1_1', 'IND_BOM_1_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pd.concat([X_valid_class_0, X_valid_class_1])\n",
    "y_valid = np.concatenate((y_valid_class_0, y_valid_class_1))\n",
    "X_valid = X_valid.drop(['class', 'IND_BOM_1_1', 'IND_BOM_1_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test_class_0, X_test_class_1])\n",
    "y_test = np.concatenate((y_test_class_0, y_test_class_1))\n",
    "X_test = X_test.drop(['class', 'IND_BOM_1_1', 'IND_BOM_1_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYXB8xrPGsxn",
    "outputId": "ff3ec40c-36e3-4733-9e8d-ea20e47340c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de entradas para treino: 194598 194598\n",
      "Quantidade de entradas para validação: 97298 97298\n",
      "Quantidade de entradas para teste: 97300 97300\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de entradas para treino:', len(X_train), len(y_train))\n",
    "print('Quantidade de entradas para validação:', len(X_valid), len(y_valid))\n",
    "print('Quantidade de entradas para teste:', len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgyWPQ9BGe3Q"
   },
   "source": [
    "#### Oversampling - Replicar a classe minoritária para ficar do tamanho da classe majoritária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5DFkN-JbH-AC",
    "outputId": "dc766e29-8e9b-4928-f09c-209cf07c3a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade antes do over sampling\n",
      "Quantidade classe 0 treino: 127549\n",
      "Quantidade classe 1 treino: 67049\n",
      "Quantidade classe 0 valid: 63774\n",
      "Quantidade classe 1 valid: 33524\n",
      "Quantidade classe 0 test: 63775\n",
      "Quantidade classe 1 test: 33525\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade antes do over sampling')\n",
    "print('Quantidade classe 0 treino:', (y_train == 0).sum())\n",
    "print('Quantidade classe 1 treino:', (y_train == 1).sum())\n",
    "print('Quantidade classe 0 valid:', (y_valid == 0).sum())\n",
    "print('Quantidade classe 1 valid:', (y_valid == 1).sum())\n",
    "print('Quantidade classe 0 test:', (y_test == 0).sum())\n",
    "print('Quantidade classe 1 test:', (y_test == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0uainKjAHCRU"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKABwcJjGnmp",
    "outputId": "a12c51de-5554-409c-e483-5c26d1c3edf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade classe 0 treino: 127549\n",
      "Quantidade classe 1 treino: 127549\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade classe 0 treino:', (y_train == 0).sum())\n",
    "print('Quantidade classe 1 treino:', (y_train == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1kmypf-nG-13"
   },
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_valid, y_valid = oversample.fit_resample(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EoeqqfV2G-_y",
    "outputId": "d7d7e19c-65dd-4e93-b359-649ce32e5c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade classe 0 valid: 63774\n",
      "Quantidade classe 1 valid: 63774\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade classe 0 valid:', (y_valid == 0).sum())\n",
    "print('Quantidade classe 1 valid:', (y_valid == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90TA_PmcG_SM",
    "outputId": "e000f1b9-513c-4bce-8ee6-f60f05f58eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade classe 0 test: 63775\n",
      "Quantidade classe 1 test: 33525\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade classe 0 test:', (y_test == 0).sum())\n",
    "print('Quantidade classe 1 test:', (y_test == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wj8xxC5c4qDQ"
   },
   "source": [
    "#### Funções auxiliares para métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas utilizadas:\n",
    "\n",
    "- Acurácia\n",
    "\n",
    "- Recall\n",
    "\n",
    "- Precision\n",
    "\n",
    "- F1-Score\n",
    "\n",
    "- Auroc (Área sob a Curva Roc)\n",
    "\n",
    "- Matriz de confusão\n",
    "      [TP  FP]\n",
    "      [FN  TN]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9agHcvcrFDIf"
   },
   "outputs": [],
   "source": [
    "### VALIDAR: Teste estatístico Kolmogorov-Smirnov -KS (principal)\n",
    "### TODO: Adiconar alguns plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "TYEt721Q4t7Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "g4vvpND1-2Il"
   },
   "outputs": [],
   "source": [
    "def print_metrics(actual, pred, pred_proba):\n",
    "  print('Accuracy: {:.4f}'.format(accuracy_score(actual, pred)))\n",
    "  print('Recall: {:.4f}'.format(recall_score(actual, pred)))\n",
    "  print('Precision: {:.4f}'.format(precision_score(actual, pred)))\n",
    "  print('F1-Score: {:.4f}'.format(f1_score(actual, pred)))\n",
    "  if pred_proba:\n",
    "    print('ROC AUC Score: {:.4f}'.format(roc_auc_score(actual, pred_proba[:, 1])))\n",
    "  print('Matriz de confusão no conjunto de teste:')\n",
    "  print(confusion_matrix(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "  accuracy = accuracy_score(actual, pred)\n",
    "  recall = recall_score(actual, pred)\n",
    "  precision = precision_score(actual, pred)\n",
    "  f1 = f1_score(actual, pred)\n",
    "  return accuracy, recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição dos principais parâmetros:\n",
    "\n",
    "- C\n",
    "  - Parâmetro de regularização. A força da regularização é inversamente proporcional a C. Deve ser estritamente positiva. A penalidade é uma penalidade de 12 ao quadrado.\n",
    "\n",
    "- kernel\n",
    "  - Especifica o tipo de kernel a ser usado no algoritmo. Se nenhum for fornecido, 'rbf' será usado. Se um callable for fornecido, ele será usado para pré-computar a matriz do kernel a partir de matrizes de dados; essa matriz deve ser uma matriz de forma\n",
    "  - Valor default: rbf\n",
    "\n",
    "- degree\n",
    "  - Grau da função kernel polinomial ('poli'). Ignorado por todos os outros kernels.\n",
    "  - Valor default: 3\n",
    "\n",
    "- gamma\n",
    "  - Coeficiente de kernel para 'rbf', 'poli' e 'sigmóide'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(gamma='auto', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:251\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    250\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[0;32m--> 251\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m    252\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:333\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    319\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    321\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    323\u001b[0m (\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[1;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[1;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[1;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[1;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[1;32m    329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[1;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[1;32m    331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[1;32m    332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[0;32m--> 333\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    334\u001b[0m     X,\n\u001b[1;32m    335\u001b[0m     y,\n\u001b[1;32m    336\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[1;32m    337\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    338\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight_,\n\u001b[1;32m    339\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[1;32m    340\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m    341\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[1;32m    342\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[1;32m    343\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[1;32m    344\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[1;32m    345\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m    346\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[1;32m    347\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[1;32m    348\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[1;32m    349\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[1;32m    350\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    351\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[1;32m    352\u001b[0m )\n\u001b[1;32m    354\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "y_valid_pred_svm = clf_svm.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_proba_svm = clf_svm.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Métricas da 1ª configuração do SVM:\\n')\n",
    "print_metrics(y_valid, y_valid_pred_svm, y_valid_proba_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segundo a própria documentação do Scikit learn para dataset muito grandes é aconselhável usarmos o LinearSVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_svm_linear = LinearSVC(random_state=0, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 29s, sys: 599 ms, total: 2min 29s\n",
      "Wall time: 2min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luizkof/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(random_state=0, tol=1e-05)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=0, tol=1e-05)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(random_state=0, tol=1e-05)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_svm_linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred_svm_linear = clf_svm_linear.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do SVM SVC Linear:\n",
      "\n",
      "Recall: 0.6593\n",
      "Precision: 0.7668\n",
      "F1-Score: 0.7090\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[50988 12786]\n",
      " [21730 42044]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do SVM SVC Linear:\\n')\n",
    "print_metrics(y_valid, y_valid_pred_svm_linear,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYwhyxkdEt16"
   },
   "source": [
    "### Modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAZM1rGKHb-7"
   },
   "source": [
    "Descrição dos parâmetros:\n",
    "\n",
    "- n_estimators\n",
    "  - O número de árvores na floresta.\n",
    "\n",
    "- criterion\n",
    "  - A função para medir a qualidade de uma divisão\n",
    "\n",
    "- max_depth\n",
    "  - A profundidade máxima da árvore.\n",
    "  - 'None' significa que os nós são expandidos até que todas as folhas sejam puras(se o nó possui prediz apenas 1 classe) ou até que todas as folhas contenham menos de min_samples_split amostras.\n",
    "\n",
    "- min_samples_split\n",
    "  - O número mínimo de amostras necessárias para dividir um nó.\n",
    "\n",
    "- min_samples_leaf\n",
    "  - O número mínimo de amostrar necessárias para ser um nó folha.\n",
    "\n",
    "- max_features\n",
    "  - O número de features a serem considerados ao procurar a melhor divisão. Por exemplo, caso a função seja 'sqrt', a cada divisão ele tenta buscar uma condição que possua sqrt(n_node) entradas. \n",
    "\n",
    "- max_leaf_nodes\n",
    "  - O número max de nós folha. \n",
    "  - 'None' significa então pode haver um número ilimitado de nós folha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "sHmEuyCIEv7O"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dNd5Uvg4fjC"
   },
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HDyP542CdtN"
   },
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- n_estimators = 100\n",
    "\n",
    "- criterion = 'gini'\n",
    "\n",
    "- max_depth = None \n",
    "\n",
    "- min_samples_split = 2\n",
    "\n",
    "- min_samples_leaf = 1\n",
    "\n",
    "- max_features = 'sqrt'\n",
    "\n",
    "- max_leaf_nodes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "kIs_MMjkhsU5"
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bluXpSrShs9A",
    "outputId": "cfb3b8d7-8054-43b4-9535-50c2da3d924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 6s\n",
      "Wall time: 40 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_rf = clf_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "yb7fjHhZhtPs"
   },
   "outputs": [],
   "source": [
    "y_valid_pred_rf = clf_rf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "HGTVUGv0CJ07"
   },
   "outputs": [],
   "source": [
    "y_valid_proba_rf = clf_rf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Z1S6I96qLQ"
   },
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0smRYcg6rsc",
    "outputId": "d80c2163-462c-4353-d3ef-660befa28a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do Random Forest:\n",
      "\n",
      "Accuracy: 0.7333\n",
      "Recall: 0.6483\n",
      "Precision: 0.7811\n",
      "F1-Score: 0.7085\n",
      "ROC AUC Score: 0.8140\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[52191 11583]\n",
      " [22432 41342]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do Random Forest:\\n')\n",
    "print_metrics(y_valid, y_valid_pred_rf, y_valid_proba_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVdid7yEMS8"
   },
   "source": [
    "#### 2ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7nArA2JE1Zk"
   },
   "source": [
    "Para a segunda configuração vamos criar um estudo de caso usando o optuna, variando alguns hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/23 09:49:51 INFO mlflow.tracking.fluent: Experiment with name 'validacao' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/jonat/Documents/UFPE/redes-neurais/mlruns/1', experiment_id='1', lifecycle_stage='active', name='validacao', tags={}>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "mlflow.set_experiment('validacao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "-X1R61biD1G4"
   },
   "outputs": [],
   "source": [
    "def random_forest(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 100),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n",
    "    }\n",
    "    # Create the model\n",
    "    with mlflow.start_run(run_name=\"Random Forest - Validacao\"):\n",
    "        rnd_forest = RandomForestClassifier(\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            min_samples_split=params[\"min_samples_split\"],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        rnd_forest.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_valid = rnd_forest.predict(X_valid)\n",
    "        y_pred_proba = rnd_forest.predict_proba(X_valid)\n",
    "\n",
    "        (accuracy, recall, precision, f1) = eval_metrics(y_valid, y_pred_valid)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "        gc.collect()\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-23 11:42:52,375]\u001b[0m A new study created in memory with name: no-name-a6b8ffed-5489-496c-a98e-fecfefd91933\u001b[0m\n",
      "2022/09/23 11:43:40 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:43:48,221]\u001b[0m Trial 0 finished with value: 0.6875842819957977 and parameters: {'n_estimators': 307, 'max_depth': 5, 'min_samples_split': 35}. Best is trial 0 with value: 0.6875842819957977.\u001b[0m\n",
      "2022/09/23 11:45:58 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:46:07,468]\u001b[0m Trial 1 finished with value: 0.7439630570451908 and parameters: {'n_estimators': 336, 'max_depth': 88, 'min_samples_split': 57}. Best is trial 1 with value: 0.7439630570451908.\u001b[0m\n",
      "2022/09/23 11:47:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:47:37,939]\u001b[0m Trial 2 finished with value: 0.7427243077116066 and parameters: {'n_estimators': 201, 'max_depth': 90, 'min_samples_split': 36}. Best is trial 1 with value: 0.7439630570451908.\u001b[0m\n",
      "2022/09/23 11:49:35 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:49:43,158]\u001b[0m Trial 3 finished with value: 0.7419638097030138 and parameters: {'n_estimators': 290, 'max_depth': 88, 'min_samples_split': 40}. Best is trial 1 with value: 0.7439630570451908.\u001b[0m\n",
      "2022/09/23 11:51:23 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:51:32,514]\u001b[0m Trial 4 finished with value: 0.7409994668673754 and parameters: {'n_estimators': 237, 'max_depth': 47, 'min_samples_split': 16}. Best is trial 1 with value: 0.7439630570451908.\u001b[0m\n",
      "2022/09/23 11:52:08 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:52:12,414]\u001b[0m Trial 5 finished with value: 0.7408897042681971 and parameters: {'n_estimators': 83, 'max_depth': 78, 'min_samples_split': 64}. Best is trial 1 with value: 0.7439630570451908.\u001b[0m\n",
      "2022/09/23 11:52:57 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:53:02,902]\u001b[0m Trial 6 finished with value: 0.7414228368927777 and parameters: {'n_estimators': 102, 'max_depth': 35, 'min_samples_split': 54}. Best is trial 1 with value: 0.7439630570451908.\u001b[0m\n",
      "2022/09/23 11:54:59 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:55:06,846]\u001b[0m Trial 7 finished with value: 0.7440336187160912 and parameters: {'n_estimators': 318, 'max_depth': 66, 'min_samples_split': 73}. Best is trial 7 with value: 0.7440336187160912.\u001b[0m\n",
      "2022/09/23 11:55:54 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:55:59,662]\u001b[0m Trial 8 finished with value: 0.7410543481669646 and parameters: {'n_estimators': 120, 'max_depth': 83, 'min_samples_split': 46}. Best is trial 7 with value: 0.7440336187160912.\u001b[0m\n",
      "2022/09/23 11:57:15 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\models\\signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-23 11:57:21,199]\u001b[0m Trial 9 finished with value: 0.7422068554583372 and parameters: {'n_estimators': 220, 'max_depth': 21, 'min_samples_split': 76}. Best is trial 7 with value: 0.7440336187160912.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rf = optuna.create_study(direction=\"maximize\")\n",
    "rf.optimize(random_forest, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYwhyxkdEt16"
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAZM1rGKHb-7"
   },
   "source": [
    "Descrição dos parâmetros:\n",
    "\n",
    "- n_estimators\n",
    "  - O número de árvores na floresta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "sHmEuyCIEv7O"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dNd5Uvg4fjC"
   },
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HDyP542CdtN"
   },
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- n_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sklearn_compatible_model():\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, activation='tanh', input_dim=input_dim))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "kIs_MMjkhsU5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4606/3075366852.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  clf_mlp = KerasClassifier(build_fn=create_sklearn_compatible_model,\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = KerasClassifier(build_fn=create_sklearn_compatible_model, \n",
    "                          batch_size=64, epochs=100,\n",
    "                          verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bluXpSrShs9A",
    "outputId": "cfb3b8d7-8054-43b4-9535-50c2da3d924a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 23:54:28.323084: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 495910512 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 1s, sys: 43.6 s, total: 8min 45s\n",
      "Wall time: 5min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab03124730>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "yb7fjHhZhtPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  91/3986 [..............................] - ETA: 4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 00:00:08.716645: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 247953312 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3986 [==============================] - 4s 908us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_mlp = clf_mlp.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "HGTVUGv0CJ07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  35/3986 [..............................] - ETA: 17s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-23 00:00:14.785572: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 247953312 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3986 [==============================] - 4s 921us/step\n"
     ]
    }
   ],
   "source": [
    "y_proba_mlp = clf_mlp.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Z1S6I96qLQ"
   },
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0smRYcg6rsc",
    "outputId": "d80c2163-462c-4353-d3ef-660befa28a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do Random Forest:\n",
      "\n",
      "Accuracy: 0.7325\n",
      "Recall: 0.6387\n",
      "Precision: 0.7862\n",
      "F1-Score: 0.7048\n",
      "ROC AUC Score: 0.8154\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[52694 11080]\n",
      " [23039 40735]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do Random Forest:\\n')\n",
    "print_metrics(y_valid, y_pred_mlp, y_proba_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVdid7yEMS8"
   },
   "source": [
    "#### 2ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7nArA2JE1Zk"
   },
   "source": [
    "Para a segunda configuração alteramos os seguintes parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X1R61biD1G4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYwhyxkdEt16"
   },
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAZM1rGKHb-7"
   },
   "source": [
    "Descrição dos parâmetros:\n",
    "\n",
    "- loss\n",
    "  - Possíveis valores: ‘log_loss’, ‘exponential’\n",
    "  - default=’log_loss’\n",
    "  - A função de perda a ser otimizada. \n",
    "    - 'log_loss' refere-se ao desvio binomial e multinomial, o mesmo usado na regressão logística. É uma boa escolha para classificação com saídas probabilísticas. \n",
    "    - 'exponencial', o aumento de gradiente recupera o algoritmo AdaBoost.\n",
    "\n",
    "- learning_rate\n",
    "  - Possíveis valores: intervalo (0,0, inf)\n",
    "  - default=0.1\n",
    "  - A taxa de aprendizado reduz a contribuição de cada árvore por learning_rate. Há um trade-off entre learning_rate e n_estimators. \n",
    "\n",
    "- n_estimators\n",
    "  - Os valores devem estar no intervalo [1, inf).\n",
    "  - default=100\n",
    "  - O número de estágios de reforço a serem executados. \n",
    "  - **O aumento de gradiente é bastante robusto ao over-fitting, portanto, um número grande geralmente resulta em melhor desempenho.\n",
    "\n",
    "- subsample\n",
    "  - Os valores devem estar no intervalo (0,0, 1,0].\n",
    "  - default=1.0\n",
    "  - A fração de amostras a ser usada para ajustar os 'individual base learners'. \n",
    "  - Se menor que 1,0, isso resulta em aumento de gradiente estocástico. subamostra interage com o parâmetro n_estimators. \n",
    "    - **Escolher subamostra < 1,0 leva a uma redução da variância e a um aumento no viés.\n",
    "\n",
    "- criterion\n",
    "  - Possíveis valores: {‘friedman_mse’, ‘squared_error’, ‘mse’}\n",
    "  - default=’friedman_mse’\n",
    "  - A função para medir a qualidade de uma divisão. \n",
    "  - Os critérios suportados são:\n",
    "    - ‘friedman_mse’ para o erro quadrático médio com pontuação de melhoria por Friedman, \n",
    "    - ‘squared_error’ para erro quadrático médio. \n",
    "  - **O valor padrão de ‘friedman_mse’ geralmente é o melhor, pois pode fornecer uma melhor aproximação em alguns casos.\n",
    "\n",
    "- min_samples_split\n",
    "  - Possíveis valores: int or float\n",
    "  - default=2\n",
    "  - Se int, os valores devem estar no intervalo [1, inf).\n",
    "  - Se float, os valores devem estar no intervalo (0.0, 1.0] e min_samples_leaf será ceil(min_samples_leaf * n_samples).\n",
    "\n",
    "- min_samples_leaf\n",
    "  - Possíveis valores: int or float\n",
    "  - default=1\n",
    "  - Isso pode ter o efeito de suavizar o modelo, especialmente na regressão.\n",
    "\n",
    "- min_weight_fraction_leaf\n",
    "  - Os valores devem estar no intervalo [0,0, 0,5].\n",
    "  - default=0.0(As amostras têm peso igual)\n",
    "  - A fração ponderada mínima da soma total de pesos (de todas as amostras de entrada) necessária para estar em um nó folha. \n",
    "\n",
    "- max_depth\n",
    "  - Os valores devem estar no intervalo [1, inf).\n",
    "  - default=3\n",
    "  - Ajuste este parâmetro para melhorar o desempenho; \n",
    "    - O melhor valor depende da interação das variáveis de entrada.\n",
    "\n",
    "- min_impurity_decrease\n",
    "  - Os valores devem estar no intervalo [0,0, inf).\n",
    "  - default=0.0\n",
    "  - Um nó será dividido se esta divisão induzir uma diminuição da impureza maior ou igual a este valor.\n",
    "\n",
    "- init\n",
    "  - Possíveis valores: estimator or ‘zero’\n",
    "  - default=None(é usado um DummyEstimator)\n",
    "  - Um objeto estimador que é usado para calcular as previsões iniciais. \n",
    "  - init tem que fornecer fit e predict_proba. \n",
    "  - Se 'zero', as previsões brutas iniciais são definidas como zero. \n",
    "\n",
    "- max_features\n",
    "  - Possíveis valores: {‘auto’, ‘sqrt’, ‘log2’}, int or float\n",
    "    - Se int, valores devem estar no intervalo  [1, inf).\n",
    "    - Se float, valores devem estar no intervalo  (0.0, 1.0] and the features considered at each split will be max(1, int(max_features * n_features_in_)).\n",
    "    - Se f = ‘auto’, ‘sqrt’, ‘log2’, então max_features = f(n_features).\n",
    "    - Se None, então max_features = n_features.\n",
    "  - default=None\n",
    "  - O número de features para considerar quando buscar pelo melhor split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "sHmEuyCIEv7O"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dNd5Uvg4fjC"
   },
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HDyP542CdtN"
   },
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- loss\n",
    "  - default=’log_loss’\n",
    "\n",
    "- learning_rate\n",
    "  - default=0.1\n",
    "\n",
    "- n_estimators\n",
    "  - default=100\n",
    "\n",
    "- subsample\n",
    "  - default=1.0\n",
    "\n",
    "- criterion\n",
    "  - default=’friedman_mse’\n",
    "\n",
    "- min_samples_split\n",
    "  - default=2\n",
    "\n",
    "- min_samples_leaf\n",
    "  - default=1\n",
    "\n",
    "- min_weight_fraction_leaf\n",
    "  - default=0.0(As amostras têm peso igual)\n",
    "\n",
    "- max_depth\n",
    "  - default=3\n",
    "\n",
    "- min_impurity_decrease\n",
    "  - default=0.0\n",
    "\n",
    "- init\n",
    "  - default=None(é usado um DummyEstimator)\n",
    "\n",
    "- max_features\n",
    "  - default=None(então max_features = n_features.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "kIs_MMjkhsU5"
   },
   "outputs": [],
   "source": [
    "clf_gb = GradientBoostingClassifier(random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bluXpSrShs9A",
    "outputId": "cfb3b8d7-8054-43b4-9535-50c2da3d924a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/23 13:26:38 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'ca2f511133b8448cbd529bd2a18fb4e5', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jonat\\Documents\\UFPE\\redes-neurais\\projeto_redes_neurais.ipynb Célula: 82\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jonat/Documents/UFPE/redes-neurais/projeto_redes_neurais.ipynb#Y143sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clf_gb\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:555\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m     patch_function\u001b[39m.\u001b[39mcall(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    557\u001b[0m session\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msucceeded\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m try_log_autologging_event(\n\u001b[0;32m    560\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_success,\n\u001b[0;32m    561\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    565\u001b[0m     kwargs,\n\u001b[0;32m    566\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:254\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[1;34m(original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m     managed_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[0;32m    253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     result \u001b[39m=\u001b[39m patch_function(original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m    256\u001b[0m     \u001b[39m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[0;32m    257\u001b[0m     \u001b[39m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[39m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m managed_run:\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1538\u001b[0m, in \u001b[0;36m_autolog.<locals>.patched_fit\u001b[1;34m(fit_impl, original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1534\u001b[0m \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mshould_log():\n\u001b[0;32m   1535\u001b[0m     \u001b[39m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m     \u001b[39m# so we need temporarily disable the post_training_metrics patching.\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m     \u001b[39mwith\u001b[39;00m _AUTOLOGGING_METRICS_MANAGER\u001b[39m.\u001b[39mdisable_log_post_training_metrics():\n\u001b[1;32m-> 1538\u001b[0m         result \u001b[39m=\u001b[39m fit_impl(original, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m     \u001b[39mif\u001b[39;00m should_log_post_training_metrics:\n\u001b[0;32m   1540\u001b[0m         _AUTOLOGGING_METRICS_MANAGER\u001b[39m.\u001b[39mregister_model(\n\u001b[0;32m   1541\u001b[0m             \u001b[39mself\u001b[39m, mlflow\u001b[39m.\u001b[39mactive_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m   1542\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1330\u001b[0m, in \u001b[0;36m_autolog.<locals>.fit_mlflow\u001b[1;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1328\u001b[0m _log_pretraining_metadata(autologging_client, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1329\u001b[0m params_logging_future \u001b[39m=\u001b[39m autologging_client\u001b[39m.\u001b[39mflush(synchronous\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1330\u001b[0m fit_output \u001b[39m=\u001b[39m original(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1331\u001b[0m _log_posttraining_metadata(autologging_client, \u001b[39mself\u001b[39m, X, y_true, sample_weight)\n\u001b[0;32m   1332\u001b[0m autologging_client\u001b[39m.\u001b[39mflush(synchronous\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:536\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[0;32m    534\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[1;32m--> 536\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:471\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[1;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    464\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[0;32m    465\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         og_kwargs,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 471\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39mog_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mog_kwargs)\n\u001b[0;32m    473\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    474\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[0;32m    475\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m         og_kwargs,\n\u001b[0;32m    480\u001b[0m     )\n\u001b[0;32m    481\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:533\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[1;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    530\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    531\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    532\u001b[0m ):\n\u001b[1;32m--> 533\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[0;32m    534\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:668\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resize_state()\n\u001b[0;32m    667\u001b[0m \u001b[39m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 668\u001b[0m n_stages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stages(\n\u001b[0;32m    669\u001b[0m     X,\n\u001b[0;32m    670\u001b[0m     y,\n\u001b[0;32m    671\u001b[0m     raw_predictions,\n\u001b[0;32m    672\u001b[0m     sample_weight,\n\u001b[0;32m    673\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    674\u001b[0m     X_val,\n\u001b[0;32m    675\u001b[0m     y_val,\n\u001b[0;32m    676\u001b[0m     sample_weight_val,\n\u001b[0;32m    677\u001b[0m     begin_at_stage,\n\u001b[0;32m    678\u001b[0m     monitor,\n\u001b[0;32m    679\u001b[0m )\n\u001b[0;32m    681\u001b[0m \u001b[39m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    682\u001b[0m \u001b[39mif\u001b[39;00m n_stages \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:745\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    738\u001b[0m     old_oob_score \u001b[39m=\u001b[39m loss_(\n\u001b[0;32m    739\u001b[0m         y[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    740\u001b[0m         raw_predictions[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    741\u001b[0m         sample_weight[\u001b[39m~\u001b[39msample_mask],\n\u001b[0;32m    742\u001b[0m     )\n\u001b[0;32m    744\u001b[0m \u001b[39m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m raw_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_stage(\n\u001b[0;32m    746\u001b[0m     i,\n\u001b[0;32m    747\u001b[0m     X,\n\u001b[0;32m    748\u001b[0m     y,\n\u001b[0;32m    749\u001b[0m     raw_predictions,\n\u001b[0;32m    750\u001b[0m     sample_weight,\n\u001b[0;32m    751\u001b[0m     sample_mask,\n\u001b[0;32m    752\u001b[0m     random_state,\n\u001b[0;32m    753\u001b[0m     X_csc,\n\u001b[0;32m    754\u001b[0m     X_csr,\n\u001b[0;32m    755\u001b[0m )\n\u001b[0;32m    757\u001b[0m \u001b[39m# track deviance (= loss)\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[39mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:247\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    244\u001b[0m     sample_weight \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m sample_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m    246\u001b[0m X \u001b[39m=\u001b[39m X_csr \u001b[39mif\u001b[39;00m X_csr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\n\u001b[1;32m--> 247\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, residual, sample_weight\u001b[39m=\u001b[39;49msample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    249\u001b[0m \u001b[39m# update tree leaves\u001b[39;00m\n\u001b[0;32m    250\u001b[0m loss\u001b[39m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    251\u001b[0m     tree\u001b[39m.\u001b[39mtree_,\n\u001b[0;32m    252\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m     k\u001b[39m=\u001b[39mk,\n\u001b[0;32m    260\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:555\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m     patch_function\u001b[39m.\u001b[39mcall(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 555\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    557\u001b[0m session\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msucceeded\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m try_log_autologging_event(\n\u001b[0;32m    560\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_success,\n\u001b[0;32m    561\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    565\u001b[0m     kwargs,\n\u001b[0;32m    566\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:254\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[1;34m(original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m     managed_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[0;32m    253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 254\u001b[0m     result \u001b[39m=\u001b[39m patch_function(original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    255\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m    256\u001b[0m     \u001b[39m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[0;32m    257\u001b[0m     \u001b[39m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[0;32m    258\u001b[0m     \u001b[39m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[0;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m managed_run:\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:1545\u001b[0m, in \u001b[0;36m_autolog.<locals>.patched_fit\u001b[1;34m(fit_impl, original, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1543\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m   1544\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1545\u001b[0m     \u001b[39mreturn\u001b[39;00m original(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:536\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[0;32m    534\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[1;32m--> 536\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:471\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[1;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    464\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[0;32m    465\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         og_kwargs,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 471\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39mog_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mog_kwargs)\n\u001b[0;32m    473\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    474\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[0;32m    475\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m         og_kwargs,\n\u001b[0;32m    480\u001b[0m     )\n\u001b[0;32m    481\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:533\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[1;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[0;32m    528\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    530\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    531\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    532\u001b[0m ):\n\u001b[1;32m--> 533\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[0;32m    534\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1314\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \n\u001b[0;32m   1316\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1342\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1343\u001b[0m         X,\n\u001b[0;32m   1344\u001b[0m         y,\n\u001b[0;32m   1345\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1346\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    449\u001b[0m         splitter,\n\u001b[0;32m    450\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "yb7fjHhZhtPs"
   },
   "outputs": [],
   "source": [
    "y_pred_gb = clf_gb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "HGTVUGv0CJ07"
   },
   "outputs": [],
   "source": [
    "y_proba_gb = clf_gb.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Z1S6I96qLQ"
   },
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0smRYcg6rsc",
    "outputId": "d80c2163-462c-4353-d3ef-660befa28a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do Random Forest:\n",
      "\n",
      "Accuracy: 0.7494\n",
      "Recall: 0.6769\n",
      "Precision: 0.7917\n",
      "F1-Score: 0.7298\n",
      "ROC AUC Score: 0.8323\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[52416 11358]\n",
      " [20607 43167]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do Random Forest:\\n')\n",
    "print_metrics(y_valid, y_pred_gb, y_proba_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVdid7yEMS8"
   },
   "source": [
    "#### 2ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7nArA2JE1Zk"
   },
   "source": [
    "Para a segunda configuração alteramos os seguintes parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X1R61biD1G4"
   },
   "outputs": [],
   "source": [
    "def gradient_boosting(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate ', 0.0001, 0.1, step=0.005),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 100),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n",
    "    }\n",
    "    # Create the model\n",
    "    with mlflow.start_run(run_name=\"Gradient Boosting - Validacao\"):\n",
    "        gb = GradientBoostingClassifier(\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            min_samples_split=params[\"min_samples_split\"],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        gb.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_valid = gb.predict(X_valid)\n",
    "        y_pred_proba = gb.predict_proba(X_valid)\n",
    "\n",
    "        (accuracy, recall, precision, f1) = eval_metrics(y_valid, y_pred_valid)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "        gc.collect()\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obLxjSMSD1MV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a68ab044c6ea367198d7b58f0f8352272d5267d2d2c131306c104f6e9ede3d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
