{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: optuna in /home/ubuntu/.local/lib/python3.7/site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.7/site-packages (from optuna) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: colorlog in /home/ubuntu/.local/lib/python3.7/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: PyYAML in /home/anaconda/lib/python3.7/site-packages (from optuna) (5.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from optuna) (1.4.41)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /home/ubuntu/.local/lib/python3.7/site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from optuna) (1.7.3)\n",
      "Requirement already satisfied: tqdm in /home/anaconda/lib/python3.7/site-packages (from optuna) (4.31.1)\n",
      "Requirement already satisfied: cliff in /home/ubuntu/.local/lib/python3.7/site-packages (from optuna) (3.10.1)\n",
      "Requirement already satisfied: Mako in /home/anaconda/lib/python3.7/site-packages (from alembic>=1.5.0->optuna) (1.0.10)\n",
      "Requirement already satisfied: importlib-resources in /home/ubuntu/.local/lib/python3.7/site-packages (from alembic>=1.5.0->optuna) (5.9.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ubuntu/.local/lib/python3.7/site-packages (from alembic>=1.5.0->optuna) (4.12.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/anaconda/lib/python3.7/site-packages (from packaging>=20.0->optuna) (2.3.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/anaconda/lib/python3.7/site-packages (from sqlalchemy>=1.3.0->optuna) (0.4.15)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from cliff->optuna) (5.10.0)\n",
      "Requirement already satisfied: autopage>=0.4.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from cliff->optuna) (3.5.0)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /home/ubuntu/.local/lib/python3.7/site-packages (from cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /home/anaconda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (19.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/.local/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (4.3.0)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /home/ubuntu/.local/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /home/anaconda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.1.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.local/lib/python3.7/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/anaconda/lib/python3.7/site-packages (from Mako->alembic>=1.5.0->optuna) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: mlflow in /home/ubuntu/.local/lib/python3.7/site-packages (1.29.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.local/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<5,>=3.7.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (4.12.0)\n",
      "Requirement already satisfied: gunicorn<21 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: entrypoints<1 in /home/anaconda/lib/python3.7/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: packaging<22 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (21.3)\n",
      "Requirement already satisfied: gitpython<4,>=2.1.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (3.1.27)\n",
      "Requirement already satisfied: Flask<3 in /home/anaconda/lib/python3.7/site-packages (from mlflow) (1.0.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/anaconda/lib/python3.7/site-packages (from mlflow) (7.0)\n",
      "Requirement already satisfied: pytz<2023 in /home/anaconda/lib/python3.7/site-packages (from mlflow) (2018.9)\n",
      "Requirement already satisfied: numpy<2 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (1.21.6)\n",
      "Requirement already satisfied: databricks-cli<1,>=0.8.7 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (0.17.3)\n",
      "Requirement already satisfied: pandas<2 in /home/anaconda/lib/python3.7/site-packages (from mlflow) (0.24.2)\n",
      "Requirement already satisfied: querystring-parser<2 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (4.21.6)\n",
      "Requirement already satisfied: docker<7,>=4.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (6.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (2.28.1)\n",
      "Requirement already satisfied: alembic<2 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (1.8.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (0.4.3)\n",
      "Requirement already satisfied: scipy<2 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (1.7.3)\n",
      "Requirement already satisfied: sqlalchemy<2,>=1.4.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (1.4.41)\n",
      "Requirement already satisfied: cloudpickle<3 in /home/anaconda/lib/python3.7/site-packages (from mlflow) (0.8.0)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/anaconda/lib/python3.7/site-packages (from mlflow) (5.1)\n",
      "Requirement already satisfied: prometheus-flask-exporter<1 in /home/ubuntu/.local/lib/python3.7/site-packages (from mlflow) (0.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/.local/lib/python3.7/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: importlib-resources in /home/ubuntu/.local/lib/python3.7/site-packages (from alembic<2->mlflow) (5.9.0)\n",
      "Requirement already satisfied: Mako in /home/anaconda/lib/python3.7/site-packages (from alembic<2->mlflow) (1.0.10)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/anaconda/lib/python3.7/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.12.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /home/ubuntu/.local/lib/python3.7/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.5.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from docker<7,>=4.0.0->mlflow) (1.4.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from docker<7,>=4.0.0->mlflow) (1.26.12)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /home/anaconda/lib/python3.7/site-packages (from Flask<3->mlflow) (0.14.1)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /home/anaconda/lib/python3.7/site-packages (from Flask<3->mlflow) (2.10)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/anaconda/lib/python3.7/site-packages (from Flask<3->mlflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.3.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.9)\n",
      "Requirement already satisfied: setuptools>=3.0 in /home/anaconda/lib/python3.7/site-packages (from gunicorn<21->mlflow) (40.8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.local/lib/python3.7/site-packages (from importlib-metadata!=4.7.0,<5,>=3.7.0->mlflow) (3.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/anaconda/lib/python3.7/site-packages (from packaging<22->mlflow) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/anaconda/lib/python3.7/site-packages (from pandas<2->mlflow) (2.8.0)\n",
      "Requirement already satisfied: prometheus-client in /home/anaconda/lib/python3.7/site-packages (from prometheus-flask-exporter<1->mlflow) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anaconda/lib/python3.7/site-packages (from requests<3,>=2.17.3->mlflow) (2019.3.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/.local/lib/python3.7/site-packages (from requests<3,>=2.17.3->mlflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anaconda/lib/python3.7/site-packages (from requests<3,>=2.17.3->mlflow) (2.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/anaconda/lib/python3.7/site-packages (from sqlalchemy<2,>=1.4.0->mlflow) (0.4.15)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/anaconda/lib/python3.7/site-packages (from Jinja2>=2.10->Flask<3->mlflow) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in /home/ubuntu/.local/lib/python3.7/site-packages (0.9.0)\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/ubuntu/.local/lib/python3.7/site-packages (from imbalanced-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from imbalanced-learn) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/.local/lib/python3.7/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user mlflow --quiet\n",
    "%pip install --user optuna\n",
    "%pip install --user mlflow scikit-learn\n",
    "%pip install -U imbalanced-learn\n",
    "%pip install -U xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import gc\n",
    "import mlflow\n",
    "import imblearn\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9QOb3wEDGFy"
   },
   "source": [
    "#### Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3YBq-Nu4KfNo"
   },
   "outputs": [],
   "source": [
    "data_path = './TRNcod.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mTti3fRBrMx5"
   },
   "outputs": [],
   "source": [
    "df_excel = pd.read_csv(data_path, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpMD8CIxubmc",
    "outputId": "2649b4cf-3a24-4bc9-f770-339eba7c1c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de entradas: 389196\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de entradas:', len(df_excel.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "34DWy_XWrl4W",
    "outputId": "1b8a7a61-84ce-44ea-b449-885b664484a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX  UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  ...  \\\n",
       "0      0     1     1     1     0     0     0     0  0.135098       1  ...   \n",
       "1      1     1     0     1     0     0     1     0  0.273504       1  ...   \n",
       "2      2     1     0     1     0     0     1     0  0.281910       0  ...   \n",
       "3      3     1     1     1     0     0     0     0  0.225741       0  ...   \n",
       "4      4     1     1     0     0     0     1     0  0.480403       0  ...   \n",
       "\n",
       "   CEP4_7  CEP4_8  CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  CEP4_14  \\\n",
       "0       0       0       1        1        0        1        1        1   \n",
       "1       0       1       0        1        1        0        0        0   \n",
       "2       1       1       0        0        0        0        1        0   \n",
       "3       1       1       0        1        1        0        1        0   \n",
       "4       1       1       1        0        0        1        0        1   \n",
       "\n",
       "   IND_BOM_1_1  IND_BOM_1_2  \n",
       "0            0            1  \n",
       "1            1            0  \n",
       "2            1            0  \n",
       "3            1            0  \n",
       "4            1            0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.drop(['INDEX'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "147wgrxQ_eCX"
   },
   "source": [
    "#### Combinando classes em uma única coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Pn9epHSQuxrG"
   },
   "outputs": [],
   "source": [
    "def label_class (row):\n",
    "   if row['IND_BOM_1_1'] == 1 and row['IND_BOM_1_2'] == 1:\n",
    "      return 2\n",
    "   if row['IND_BOM_1_1'] == 1:\n",
    "      return 0\n",
    "   if row['IND_BOM_1_2'] == 1:\n",
    "      return 1\n",
    "   return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_yoSjoMX4W57"
   },
   "outputs": [],
   "source": [
    "df['class'] = df.apply (lambda row: label_class(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "dNlLOAJJ4bYk",
    "outputId": "a3585d0e-ed05-4955-d690-537bacb7f179"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0     1     1     1     0     0     0     0  0.135098       1   \n",
       "1     1     0     1     0     0     1     0  0.273504       1   \n",
       "2     1     0     1     0     0     1     0  0.281910       0   \n",
       "3     1     1     1     0     0     0     0  0.225741       0   \n",
       "4     1     1     0     0     0     1     0  0.480403       0   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "0                        0.222222  ...       0       1        1        0   \n",
       "1                        0.111111  ...       1       0        1        1   \n",
       "2                        1.000000  ...       1       0        0        0   \n",
       "3                        0.111111  ...       1       0        1        1   \n",
       "4                        0.111111  ...       1       1        0        0   \n",
       "\n",
       "   CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  class  \n",
       "0        1        1        1            0            1      1  \n",
       "1        0        0        0            1            0      0  \n",
       "2        0        1        0            1            0      0  \n",
       "3        0        1        0            1            0      0  \n",
       "4        1        0        1            1            0      0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4R6NcieU4fVQ",
    "outputId": "dda4136c-2c6f-47e2-a590-40507fc0916a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe 0: 255098\n",
      "classe 1: 134098\n",
      "classe desconhecida: 0\n"
     ]
    }
   ],
   "source": [
    "print('classe 0:', len(df[df['class'] == 0]))\n",
    "print('classe 1:', len(df[df['class'] == 1]))\n",
    "print('classe desconhecida:', len(df[df['class'] > 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Etapa - Particionamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_class_0 = df[df['class'] == 0]\n",
    "x_class_1 = df[df['class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219323</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "1     1     0     1     0     0     1     0  0.273504       1   \n",
       "2     1     0     1     0     0     1     0  0.281910       0   \n",
       "3     1     1     1     0     0     0     0  0.225741       0   \n",
       "4     1     1     0     0     0     1     0  0.480403       0   \n",
       "5     0     1     1     0     0     0     1  0.219323       0   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "1                        0.111111  ...       1       0        1        1   \n",
       "2                        1.000000  ...       1       0        0        0   \n",
       "3                        0.111111  ...       1       0        1        1   \n",
       "4                        0.111111  ...       1       1        0        0   \n",
       "5                        0.111111  ...       1       1        0        1   \n",
       "\n",
       "   CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  class  \n",
       "1        0        0        0            1            0      0  \n",
       "2        0        1        0            1            0      0  \n",
       "3        0        1        0            1            0      0  \n",
       "4        1        0        1            1            0      0  \n",
       "5        0        0        1            1            0      0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_class_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654703</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398961</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0      1     1     1     0     0     0     0  0.135098       1   \n",
       "10     1     0     1     1     0     0     0  0.654703       0   \n",
       "11     1     1     1     0     0     0     0  0.097444       1   \n",
       "12     1     0     1     0     1     0     0  0.398961       0   \n",
       "17     1     1     1     0     0     0     0  0.142254       0   \n",
       "\n",
       "    NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "0                         0.222222  ...       0       1        1        0   \n",
       "10                        0.111111  ...       1       0        1        0   \n",
       "11                        0.111111  ...       1       0        1        0   \n",
       "12                        0.111111  ...       1       1        0        1   \n",
       "17                        0.111111  ...       0       0        1        0   \n",
       "\n",
       "    CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  class  \n",
       "0         1        1        1            0            1      1  \n",
       "10        0        0        0            0            1      1  \n",
       "11        1        0        1            0            1      1  \n",
       "12        0        0        0            0            1      1  \n",
       "17        1        0        1            0            1      1  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_class_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q5lQRWw_lr9"
   },
   "source": [
    "#### 2 Etapa - Particionamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3NInOmMP70vA"
   },
   "outputs": [],
   "source": [
    "y_class_0 = x_class_0['class'].values\n",
    "y_class_1 = x_class_1['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20hYd4oJCLNG"
   },
   "source": [
    "#### Separar dados em treino, validação e treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiKN6mFZCs21"
   },
   "source": [
    "Os dados foram divididos aleatoriamente usando o método train_test_split()\n",
    "- 50% dos dados para treinamento\n",
    "- Dos 50% restantes, metade(25% do total) pra validação e o restante(25%) para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class_0, X_rem_class_0, y_train_class_0, y_rem_class_0 = train_test_split(x_class_0, y_class_0, train_size=0.5)\n",
    "X_valid_class_0, X_test_class_0, y_valid_class_0, y_test_class_0 = train_test_split(X_rem_class_0, y_rem_class_0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class_1, X_rem_class_1, y_train_class_1, y_rem_class_1 = train_test_split(x_class_1, y_class_1, train_size=0.5)\n",
    "X_valid_class_1, X_test_class_1, y_valid_class_1, y_test_class_1 = train_test_split(X_rem_class_1, y_rem_class_1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_class_0, X_train_class_1])\n",
    "y_train = np.concatenate((y_train_class_0, y_train_class_1))\n",
    "X_train = X_train.drop(['class', 'IND_BOM_1_1', 'IND_BOM_1_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pd.concat([X_valid_class_0, X_valid_class_1])\n",
    "y_valid = np.concatenate((y_valid_class_0, y_valid_class_1))\n",
    "X_valid = X_valid.drop(['class', 'IND_BOM_1_1', 'IND_BOM_1_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test_class_0, X_test_class_1])\n",
    "y_test = np.concatenate((y_test_class_0, y_test_class_1))\n",
    "X_test = X_test.drop(['class', 'IND_BOM_1_1', 'IND_BOM_1_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYXB8xrPGsxn",
    "outputId": "ff3ec40c-36e3-4733-9e8d-ea20e47340c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de entradas para treino: 194598 194598\n",
      "Quantidade de entradas para validação: 97298 97298\n",
      "Quantidade de entradas para teste: 97300 97300\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de entradas para treino:', len(X_train), len(y_train))\n",
    "print('Quantidade de entradas para validação:', len(X_valid), len(y_valid))\n",
    "print('Quantidade de entradas para teste:', len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgyWPQ9BGe3Q"
   },
   "source": [
    "#### Oversampling - Replicar a classe minoritária para ficar do tamanho da classe majoritária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5DFkN-JbH-AC",
    "outputId": "dc766e29-8e9b-4928-f09c-209cf07c3a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade antes do over sampling\n",
      "Quantidade classe 0 treino: 127549\n",
      "Quantidade classe 1 treino: 67049\n",
      "Quantidade classe 0 valid: 63774\n",
      "Quantidade classe 1 valid: 33524\n",
      "Quantidade classe 0 test: 63775\n",
      "Quantidade classe 1 test: 33525\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade antes do over sampling')\n",
    "print('Quantidade classe 0 treino:', (y_train == 0).sum())\n",
    "print('Quantidade classe 1 treino:', (y_train == 1).sum())\n",
    "print('Quantidade classe 0 valid:', (y_valid == 0).sum())\n",
    "print('Quantidade classe 1 valid:', (y_valid == 1).sum())\n",
    "print('Quantidade classe 0 test:', (y_test == 0).sum())\n",
    "print('Quantidade classe 1 test:', (y_test == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0uainKjAHCRU"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKABwcJjGnmp",
    "outputId": "a12c51de-5554-409c-e483-5c26d1c3edf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade classe 0 treino: 127549\n",
      "Quantidade classe 1 treino: 127549\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade classe 0 treino:', (y_train == 0).sum())\n",
    "print('Quantidade classe 1 treino:', (y_train == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1kmypf-nG-13"
   },
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_valid, y_valid = oversample.fit_resample(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EoeqqfV2G-_y",
    "outputId": "d7d7e19c-65dd-4e93-b359-649ce32e5c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade classe 0 valid: 63774\n",
      "Quantidade classe 1 valid: 63774\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade classe 0 valid:', (y_valid == 0).sum())\n",
    "print('Quantidade classe 1 valid:', (y_valid == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90TA_PmcG_SM",
    "outputId": "e000f1b9-513c-4bce-8ee6-f60f05f58eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade classe 0 test: 63775\n",
      "Quantidade classe 1 test: 33525\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade classe 0 test:', (y_test == 0).sum())\n",
    "print('Quantidade classe 1 test:', (y_test == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wj8xxC5c4qDQ"
   },
   "source": [
    "#### Funções auxiliares para métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas utilizadas:\n",
    "\n",
    "- Acurácia\n",
    "\n",
    "- Recall\n",
    "\n",
    "- Precision\n",
    "\n",
    "- F1-Score\n",
    "\n",
    "- Auroc (Área sob a Curva Roc)\n",
    "\n",
    "- Matriz de confusão\n",
    "      [TP  FP]\n",
    "      [FN  TN]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9agHcvcrFDIf"
   },
   "outputs": [],
   "source": [
    "### VALIDAR: Teste estatístico Kolmogorov-Smirnov -KS (principal)\n",
    "### TODO: Adiconar alguns plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "TYEt721Q4t7Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "g4vvpND1-2Il"
   },
   "outputs": [],
   "source": [
    "def print_metrics(actual, pred, pred_proba):\n",
    "  print('Accuracy: {:.4f}'.format(accuracy_score(actual, pred)))\n",
    "  print('Recall: {:.4f}'.format(recall_score(actual, pred)))\n",
    "  print('Precision: {:.4f}'.format(precision_score(actual, pred)))\n",
    "  print('F1-Score: {:.4f}'.format(f1_score(actual, pred)))\n",
    "  print('ROC AUC Score: {:.4f}'.format(roc_auc_score(actual, pred_proba[:, 1])))\n",
    "  print('Matriz de confusão no conjunto de teste:')\n",
    "  print(confusion_matrix(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "  accuracy = accuracy_score(actual, pred)\n",
    "  recall = recall_score(actual, pred)\n",
    "  precision = precision_score(actual, pred)\n",
    "  f1 = f1_score(actual, pred)\n",
    "    # adicionar KS\n",
    "  return accuracy, recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/ubuntu/Desktop/python-machine-learning-kit/redes-neurais/mlruns/1', creation_time=1664471361376, experiment_id='1', last_update_time=1664471361376, lifecycle_stage='active', name='validacao', tags={}>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "mlflow.set_experiment('validacao')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição dos principais parâmetros:\n",
    "\n",
    "- C\n",
    "  - Parâmetro de regularização. A força da regularização é inversamente proporcional a C. Deve ser estritamente positiva. A penalidade é uma penalidade de 12 ao quadrado.\n",
    "\n",
    "- kernel\n",
    "  - Especifica o tipo de kernel a ser usado no algoritmo. Se nenhum for fornecido, 'rbf' será usado. Se um callable for fornecido, ele será usado para pré-computar a matriz do kernel a partir de matrizes de dados; essa matriz deve ser uma matriz de forma\n",
    "  - Valor default: rbf\n",
    "\n",
    "- degree\n",
    "  - Grau da função kernel polinomial ('poli'). Ignorado por todos os outros kernels.\n",
    "  - Valor default: 3\n",
    "\n",
    "- gamma\n",
    "  - Coeficiente de kernel para 'rbf', 'poli' e 'sigmóide'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(gamma='auto', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_5</th>\n",
       "      <th>CEP4_6</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512208</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.512833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.677307</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112892</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0     1     0     1     1     0     0     0  0.512208       1   \n",
       "1     1     1     0     1     0     0     0  0.512833       0   \n",
       "2     1     0     1     0     0     1     0  0.677307       0   \n",
       "3     1     1     0     0     1     0     0  0.064333       1   \n",
       "4     0     1     1     0     0     0     1  0.112892       1   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_5  CEP4_6  CEP4_7  CEP4_8  \\\n",
       "0                        0.111111  ...       1       1       0       0   \n",
       "1                        0.111111  ...       1       1       1       0   \n",
       "2                        0.111111  ...       1       0       0       0   \n",
       "3                        0.000000  ...       0       0       1       1   \n",
       "4                        0.111111  ...       0       0       1       0   \n",
       "\n",
       "   CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  CEP4_14  \n",
       "0       0        1        0        1        0        1  \n",
       "1       0        1        0        1        1        0  \n",
       "2       0        1        0        1        1        0  \n",
       "3       0        1        0        1        0        0  \n",
       "4       1        1        1        0        1        0  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# X_train2 = X_train[0:3]\n",
    "# y_train2 = [0, 1, 0]\n",
    "# clf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_valid_pred_svm = clf_svm.predict(X_valid)\n",
    "# y_valid_pred_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid_proba_svm = clf_svm.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Métricas da 1ª configuração do SVM:\\n')\n",
    "# print_metrics(y_valid, y_valid_pred_svm, y_valid_proba_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segundo a própria documentação do Scikit learn para dataset muito grandes é aconselhável usarmos o LinearSVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_svm_linear = LinearSVC(random_state=0, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/29 18:47:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '4ef9cc0f2cab4272b1b1510c507545cf', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "2022/09/29 18:51:41 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 11s, sys: 10.2 s, total: 4min 22s\n",
      "Wall time: 4min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=0, tol=1e-05)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# clf_svm_linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid_pred_svm_linear = clf_svm_linear.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do SVM SVC Linear:\n",
      "\n",
      "Accuracy: 0.7301\n",
      "Recall: 0.6573\n",
      "Precision: 0.7692\n",
      "F1-Score: 0.7089\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[51199 12575]\n",
      " [21854 41920]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do SVM SVC Linear:\\n')\n",
    "print_metrics(y_valid, y_valid_pred_svm_linear,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYwhyxkdEt16"
   },
   "source": [
    "### Modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAZM1rGKHb-7"
   },
   "source": [
    "Descrição dos parâmetros:\n",
    "\n",
    "- n_estimators\n",
    "  - O número de árvores na floresta.\n",
    "\n",
    "- criterion\n",
    "  - A função para medir a qualidade de uma divisão\n",
    "\n",
    "- max_depth\n",
    "  - A profundidade máxima da árvore.\n",
    "  - 'None' significa que os nós são expandidos até que todas as folhas sejam puras(se o nó possui prediz apenas 1 classe) ou até que todas as folhas contenham menos de min_samples_split amostras.\n",
    "\n",
    "- min_samples_split\n",
    "  - O número mínimo de amostras necessárias para dividir um nó.\n",
    "\n",
    "- min_samples_leaf\n",
    "  - O número mínimo de amostrar necessárias para ser um nó folha.\n",
    "\n",
    "- max_features\n",
    "  - O número de features a serem considerados ao procurar a melhor divisão. Por exemplo, caso a função seja 'sqrt', a cada divisão ele tenta buscar uma condição que possua sqrt(n_node) entradas. \n",
    "\n",
    "- max_leaf_nodes\n",
    "  - O número max de nós folha. \n",
    "  - 'None' significa então pode haver um número ilimitado de nós folha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "sHmEuyCIEv7O"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dNd5Uvg4fjC"
   },
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HDyP542CdtN"
   },
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- n_estimators = 100\n",
    "\n",
    "- criterion = 'gini'\n",
    "\n",
    "- max_depth = None \n",
    "\n",
    "- min_samples_split = 2\n",
    "\n",
    "- min_samples_leaf = 1\n",
    "\n",
    "- max_features = 'sqrt'\n",
    "\n",
    "- max_leaf_nodes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "kIs_MMjkhsU5"
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bluXpSrShs9A",
    "outputId": "cfb3b8d7-8054-43b4-9535-50c2da3d924a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/30 02:16:48 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '87164fc9014743b9aa8427c7f0b45360', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2022/09/30 02:17:22 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2022/09/30 02:17:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 15s, sys: 6.62 s, total: 10min 22s\n",
      "Wall time: 42.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_rf = clf_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "yb7fjHhZhtPs"
   },
   "outputs": [],
   "source": [
    "y_valid_pred_rf = clf_rf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "HGTVUGv0CJ07"
   },
   "outputs": [],
   "source": [
    "y_valid_proba_rf = clf_rf.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Z1S6I96qLQ"
   },
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0smRYcg6rsc",
    "outputId": "d80c2163-462c-4353-d3ef-660befa28a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do Random Forest:\n",
      "\n",
      "Accuracy: 0.7334\n",
      "Recall: 0.6455\n",
      "Precision: 0.7832\n",
      "F1-Score: 0.7077\n",
      "ROC AUC Score: 0.8138\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[52380 11394]\n",
      " [22607 41167]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do Random Forest:\\n')\n",
    "print_metrics(y_valid, y_valid_pred_rf, y_valid_proba_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255098"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest usando K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "scores = []\n",
    "# cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# for train_index, test_index in cv.split(X_train):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index, \"LEN:\", X_train.loc[255096:255097])\n",
    "#     X_train2, X_test2, y_train2, y_test2 = X_train[train_index], X_train[test_index], y_train[train_index], y_train[test_index]\n",
    "#     clf_rf.fit(X_train2, y_train2)\n",
    "#     scores.append(clf_rf.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76057531, 0.76244517, 0.76138395])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(clf_rf, X_train, y_train, cv=kfold, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVdid7yEMS8"
   },
   "source": [
    "# 2ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7nArA2JE1Zk"
   },
   "source": [
    "Para a segunda configuração vamos criar um estudo de caso usando o optuna, variando alguns hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-X1R61biD1G4"
   },
   "outputs": [],
   "source": [
    "def random_forest(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 100),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n",
    "    }\n",
    "    # Create the model\n",
    "    with mlflow.start_run(run_name=\"Random Forest - Validacao\"):\n",
    "        rnd_forest = RandomForestClassifier(\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            min_samples_split=params[\"min_samples_split\"],\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        rnd_forest.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_valid = rnd_forest.predict(X_valid)\n",
    "        y_pred_proba = rnd_forest.predict_proba(X_valid)\n",
    "\n",
    "        (accuracy, recall, precision, f1) = eval_metrics(y_valid, y_pred_valid)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "        gc.collect()\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-29 18:59:27,225]\u001b[0m A new study created in memory with name: no-name-60e35998-c952-4007-a110-39236862f3e1\u001b[0m\n",
      "2022/09/29 18:59:57 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:00:01,534]\u001b[0m Trial 0 finished with value: 0.7403487314579609 and parameters: {'n_estimators': 126, 'max_depth': 18, 'min_samples_split': 75}. Best is trial 0 with value: 0.7403487314579609.\u001b[0m\n",
      "2022/09/29 19:00:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:00:43,070]\u001b[0m Trial 1 finished with value: 0.7414698780067112 and parameters: {'n_estimators': 121, 'max_depth': 57, 'min_samples_split': 25}. Best is trial 1 with value: 0.7414698780067112.\u001b[0m\n",
      "2022/09/29 19:01:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:01:08,486]\u001b[0m Trial 2 finished with value: 0.7409994668673754 and parameters: {'n_estimators': 66, 'max_depth': 89, 'min_samples_split': 44}. Best is trial 1 with value: 0.7414698780067112.\u001b[0m\n",
      "2022/09/29 19:02:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:02:09,412]\u001b[0m Trial 3 finished with value: 0.7439552168595353 and parameters: {'n_estimators': 236, 'max_depth': 52, 'min_samples_split': 97}. Best is trial 3 with value: 0.7439552168595353.\u001b[0m\n",
      "2022/09/29 19:03:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:03:46,312]\u001b[0m Trial 4 finished with value: 0.7436808103615894 and parameters: {'n_estimators': 347, 'max_depth': 32, 'min_samples_split': 25}. Best is trial 3 with value: 0.7439552168595353.\u001b[0m\n",
      "2022/09/29 19:04:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:04:49,186]\u001b[0m Trial 5 finished with value: 0.744950920437796 and parameters: {'n_estimators': 236, 'max_depth': 51, 'min_samples_split': 57}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n",
      "2022/09/29 19:06:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:06:21,950]\u001b[0m Trial 6 finished with value: 0.7434377646062659 and parameters: {'n_estimators': 331, 'max_depth': 42, 'min_samples_split': 21}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n",
      "2022/09/29 19:06:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-29 19:06:46,148]\u001b[0m Trial 7 finished with value: 0.7419246087747358 and parameters: {'n_estimators': 72, 'max_depth': 62, 'min_samples_split': 85}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n",
      "2022/09/29 19:07:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:07:42,908]\u001b[0m Trial 8 finished with value: 0.7439944177878132 and parameters: {'n_estimators': 213, 'max_depth': 47, 'min_samples_split': 60}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n",
      "2022/09/29 19:08:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:08:52,312]\u001b[0m Trial 9 finished with value: 0.7443237055853482 and parameters: {'n_estimators': 262, 'max_depth': 75, 'min_samples_split': 49}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rf = optuna.create_study(direction=\"maximize\")\n",
    "rf.optimize(random_forest, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYwhyxkdEt16"
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAZM1rGKHb-7"
   },
   "source": [
    "Descrição dos parâmetros:\n",
    "\n",
    "- n_estimators\n",
    "  - O número de árvores na floresta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/ubuntu/.local/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/anaconda/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (65.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/anaconda/lib/python3.7/site-packages (from tensorflow) (1.11.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (3.19.5)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/anaconda/lib/python3.7/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/anaconda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.33.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/anaconda/lib/python3.7/site-packages (from packaging->tensorflow) (2.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ubuntu/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2019.3.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "sHmEuyCIEv7O"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dNd5Uvg4fjC"
   },
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HDyP542CdtN"
   },
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- n_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sklearn_compatible_model():\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, activation='tanh', input_dim=input_dim))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "kIs_MMjkhsU5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = KerasClassifier(build_fn=create_sklearn_compatible_model, \n",
    "                          batch_size=64, epochs=100,\n",
    "                          verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bluXpSrShs9A",
    "outputId": "cfb3b8d7-8054-43b4-9535-50c2da3d924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 39s, sys: 4min 4s, total: 22min 43s\n",
      "Wall time: 9min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73e08bccf8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "yb7fjHhZhtPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3986 [==============================] - 4s 969us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_mlp = clf_mlp.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "HGTVUGv0CJ07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3986 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_proba_mlp = clf_mlp.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Z1S6I96qLQ"
   },
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0smRYcg6rsc",
    "outputId": "d80c2163-462c-4353-d3ef-660befa28a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do Random Forest:\n",
      "\n",
      "Accuracy: 0.7295\n",
      "Recall: 0.6847\n",
      "Precision: 0.7521\n",
      "F1-Score: 0.7168\n",
      "ROC AUC Score: 0.8149\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[49379 14395]\n",
      " [20110 43664]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do Random Forest:\\n')\n",
    "print_metrics(y_valid, y_pred_mlp, y_proba_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVdid7yEMS8"
   },
   "source": [
    "#### 2ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7nArA2JE1Zk"
   },
   "source": [
    "Para a segunda configuração alteramos os seguintes parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X1R61biD1G4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYwhyxkdEt16"
   },
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAZM1rGKHb-7"
   },
   "source": [
    "Descrição dos parâmetros:\n",
    "\n",
    "- loss\n",
    "  - Possíveis valores: ‘log_loss’, ‘exponential’\n",
    "  - default=’log_loss’\n",
    "  - A função de perda a ser otimizada. \n",
    "    - 'log_loss' refere-se ao desvio binomial e multinomial, o mesmo usado na regressão logística. É uma boa escolha para classificação com saídas probabilísticas. \n",
    "    - 'exponencial', o aumento de gradiente recupera o algoritmo AdaBoost.\n",
    "\n",
    "- learning_rate\n",
    "  - Possíveis valores: intervalo (0,0, inf)\n",
    "  - default=0.1\n",
    "  - A taxa de aprendizado reduz a contribuição de cada árvore por learning_rate. Há um trade-off entre learning_rate e n_estimators. \n",
    "\n",
    "- n_estimators\n",
    "  - Os valores devem estar no intervalo [1, inf).\n",
    "  - default=100\n",
    "  - O número de estágios de reforço a serem executados. \n",
    "  - **O aumento de gradiente é bastante robusto ao over-fitting, portanto, um número grande geralmente resulta em melhor desempenho.\n",
    "\n",
    "- subsample\n",
    "  - Os valores devem estar no intervalo (0,0, 1,0].\n",
    "  - default=1.0\n",
    "  - A fração de amostras a ser usada para ajustar os 'individual base learners'. \n",
    "  - Se menor que 1,0, isso resulta em aumento de gradiente estocástico. subamostra interage com o parâmetro n_estimators. \n",
    "    - **Escolher subamostra < 1,0 leva a uma redução da variância e a um aumento no viés.\n",
    "\n",
    "- criterion\n",
    "  - Possíveis valores: {‘friedman_mse’, ‘squared_error’, ‘mse’}\n",
    "  - default=’friedman_mse’\n",
    "  - A função para medir a qualidade de uma divisão. \n",
    "  - Os critérios suportados são:\n",
    "    - ‘friedman_mse’ para o erro quadrático médio com pontuação de melhoria por Friedman, \n",
    "    - ‘squared_error’ para erro quadrático médio. \n",
    "  - **O valor padrão de ‘friedman_mse’ geralmente é o melhor, pois pode fornecer uma melhor aproximação em alguns casos.\n",
    "\n",
    "- min_samples_split\n",
    "  - Possíveis valores: int or float\n",
    "  - default=2\n",
    "  - Se int, os valores devem estar no intervalo [1, inf).\n",
    "  - Se float, os valores devem estar no intervalo (0.0, 1.0] e min_samples_leaf será ceil(min_samples_leaf * n_samples).\n",
    "\n",
    "- min_samples_leaf\n",
    "  - Possíveis valores: int or float\n",
    "  - default=1\n",
    "  - Isso pode ter o efeito de suavizar o modelo, especialmente na regressão.\n",
    "\n",
    "- min_weight_fraction_leaf\n",
    "  - Os valores devem estar no intervalo [0,0, 0,5].\n",
    "  - default=0.0(As amostras têm peso igual)\n",
    "  - A fração ponderada mínima da soma total de pesos (de todas as amostras de entrada) necessária para estar em um nó folha. \n",
    "\n",
    "- max_depth\n",
    "  - Os valores devem estar no intervalo [1, inf).\n",
    "  - default=3\n",
    "  - Ajuste este parâmetro para melhorar o desempenho; \n",
    "    - O melhor valor depende da interação das variáveis de entrada.\n",
    "\n",
    "- min_impurity_decrease\n",
    "  - Os valores devem estar no intervalo [0,0, inf).\n",
    "  - default=0.0\n",
    "  - Um nó será dividido se esta divisão induzir uma diminuição da impureza maior ou igual a este valor.\n",
    "\n",
    "- init\n",
    "  - Possíveis valores: estimator or ‘zero’\n",
    "  - default=None(é usado um DummyEstimator)\n",
    "  - Um objeto estimador que é usado para calcular as previsões iniciais. \n",
    "  - init tem que fornecer fit e predict_proba. \n",
    "  - Se 'zero', as previsões brutas iniciais são definidas como zero. \n",
    "\n",
    "- max_features\n",
    "  - Possíveis valores: {‘auto’, ‘sqrt’, ‘log2’}, int or float\n",
    "    - Se int, valores devem estar no intervalo  [1, inf).\n",
    "    - Se float, valores devem estar no intervalo  (0.0, 1.0] and the features considered at each split will be max(1, int(max_features * n_features_in_)).\n",
    "    - Se f = ‘auto’, ‘sqrt’, ‘log2’, então max_features = f(n_features).\n",
    "    - Se None, então max_features = n_features.\n",
    "  - default=None\n",
    "  - O número de features para considerar quando buscar pelo melhor split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "sHmEuyCIEv7O"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dNd5Uvg4fjC"
   },
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HDyP542CdtN"
   },
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- loss\n",
    "  - default=’log_loss’\n",
    "\n",
    "- learning_rate\n",
    "  - default=0.1\n",
    "\n",
    "- n_estimators\n",
    "  - default=100\n",
    "\n",
    "- subsample\n",
    "  - default=1.0\n",
    "\n",
    "- criterion\n",
    "  - default=’friedman_mse’\n",
    "\n",
    "- min_samples_split\n",
    "  - default=2\n",
    "\n",
    "- min_samples_leaf\n",
    "  - default=1\n",
    "\n",
    "- min_weight_fraction_leaf\n",
    "  - default=0.0(As amostras têm peso igual)\n",
    "\n",
    "- max_depth\n",
    "  - default=3\n",
    "\n",
    "- min_impurity_decrease\n",
    "  - default=0.0\n",
    "\n",
    "- init\n",
    "  - default=None(é usado um DummyEstimator)\n",
    "\n",
    "- max_features\n",
    "  - default=None(então max_features = n_features.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "kIs_MMjkhsU5"
   },
   "outputs": [],
   "source": [
    "clf_gb = xgb.XGBClassifier(random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bluXpSrShs9A",
    "outputId": "cfb3b8d7-8054-43b4-9535-50c2da3d924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 46s, sys: 672 ms, total: 15min 47s\n",
      "Wall time: 40.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=27,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "yb7fjHhZhtPs"
   },
   "outputs": [],
   "source": [
    "y_pred_gb = clf_gb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "HGTVUGv0CJ07"
   },
   "outputs": [],
   "source": [
    "y_proba_gb = clf_gb.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Z1S6I96qLQ"
   },
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0smRYcg6rsc",
    "outputId": "d80c2163-462c-4353-d3ef-660befa28a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do Random Forest:\n",
      "\n",
      "Accuracy: 0.7570\n",
      "Recall: 0.6686\n",
      "Precision: 0.8121\n",
      "F1-Score: 0.7334\n",
      "ROC AUC Score: 0.8412\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[53909  9865]\n",
      " [21135 42639]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do Random Forest:\\n')\n",
    "print_metrics(y_valid, y_pred_gb, y_proba_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVdid7yEMS8"
   },
   "source": [
    "#### 2ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7nArA2JE1Zk"
   },
   "source": [
    "Para a segunda configuração alteramos os seguintes parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "-X1R61biD1G4"
   },
   "outputs": [],
   "source": [
    "def gradient_boosting(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate ', 0.0001, 0.1, step=0.005),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 100),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300, step=10)\n",
    "    }\n",
    "    # 'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n",
    "    # Create the model\n",
    "    with mlflow.start_run(run_name=\"Gradient Boosting - Validacao\"):\n",
    "        gb_clf_trial = xgb.XGBClassifier(\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            random_state=42\n",
    "        )\n",
    "        print(\"Training model with params\", params)\n",
    "        gb_clf_trial.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_valid = gb_clf_trial.predict(X_valid)\n",
    "        y_pred_proba = gb_clf_trial.predict_proba(X_valid)\n",
    "\n",
    "        (accuracy, recall, precision, f1) = eval_metrics(y_valid, y_pred_valid)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "        gc.collect()\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 03:41:51,757]\u001b[0m A new study created in memory with name: no-name-6d9d3dc5-6165-4317-b52f-c71c0067ae07\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0751, 'max_depth': 5, 'n_estimators': 190}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 03:42:56,244]\u001b[0m Trial 0 finished with value: 0.7599570357826073 and parameters: {'learning_rate ': 0.0751, 'max_depth': 5, 'n_estimators': 190}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.08510000000000001, 'max_depth': 88, 'n_estimators': 110}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 03:49:04,054]\u001b[0m Trial 1 finished with value: 0.7464248753410481 and parameters: {'learning_rate ': 0.08510000000000001, 'max_depth': 88, 'n_estimators': 110}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0801, 'max_depth': 36, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:02:31,447]\u001b[0m Trial 2 finished with value: 0.7507761783799041 and parameters: {'learning_rate ': 0.0801, 'max_depth': 36, 'n_estimators': 300}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0951, 'max_depth': 45, 'n_estimators': 140}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:09:48,697]\u001b[0m Trial 3 finished with value: 0.748447643240192 and parameters: {'learning_rate ': 0.0951, 'max_depth': 45, 'n_estimators': 140}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0101, 'max_depth': 81, 'n_estimators': 120}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:18:12,463]\u001b[0m Trial 4 finished with value: 0.7250603694295481 and parameters: {'learning_rate ': 0.0101, 'max_depth': 81, 'n_estimators': 120}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0601, 'max_depth': 17, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:21:01,868]\u001b[0m Trial 5 finished with value: 0.7539906544986985 and parameters: {'learning_rate ': 0.0601, 'max_depth': 17, 'n_estimators': 100}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0951, 'max_depth': 75, 'n_estimators': 220}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:31:41,724]\u001b[0m Trial 6 finished with value: 0.7493257440336187 and parameters: {'learning_rate ': 0.0951, 'max_depth': 75, 'n_estimators': 220}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.015099999999999999, 'max_depth': 94, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:50:08,844]\u001b[0m Trial 7 finished with value: 0.7448411578386176 and parameters: {'learning_rate ': 0.015099999999999999, 'max_depth': 94, 'n_estimators': 300}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0751, 'max_depth': 7, 'n_estimators': 270}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:52:16,947]\u001b[0m Trial 8 finished with value: 0.7615407532850378 and parameters: {'learning_rate ': 0.0751, 'max_depth': 7, 'n_estimators': 270}. Best is trial 8 with value: 0.7615407532850378.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.015099999999999999, 'max_depth': 46, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 05:05:07,544]\u001b[0m Trial 9 finished with value: 0.7403408912723053 and parameters: {'learning_rate ': 0.015099999999999999, 'max_depth': 46, 'n_estimators': 200}. Best is trial 8 with value: 0.7615407532850378.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gb = optuna.create_study(direction=\"maximize\")\n",
    "gb.optimize(gradient_boosting, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a68ab044c6ea367198d7b58f0f8352272d5267d2d2c131306c104f6e9ede3d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
