{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\jonat\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (4.64.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (1.7.3)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (1.21.5)\n",
      "Requirement already satisfied: cliff in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (4.0.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from optuna) (1.4.32)\n",
      "Requirement already satisfied: Mako in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.1)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from cliff->optuna) (4.0.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from cliff->optuna) (2.4.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from cliff->optuna) (4.11.3)\n",
      "Requirement already satisfied: autopage>=0.4.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from cliff->optuna) (0.5.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (3.4.1)\n",
      "Requirement already satisfied: pyperclip>=1.6 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->cliff->optuna) (3.7.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from stevedore>=2.0.1->cliff->optuna) (5.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\jonat\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.2-py3-none-win_amd64.whl (125.4 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-plot\n",
      "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: joblib>=0.10 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from scikit-plot) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from scikit-plot) (3.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from scikit-plot) (1.1.2)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from scikit-plot) (1.7.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (2.2.0)\n",
      "Installing collected packages: scikit-plot\n",
      "Successfully installed scikit-plot-0.3.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna\n",
    "%pip install imbalanced-learn\n",
    "%pip install xgboost\n",
    "%pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import gc\n",
    "import imblearn\n",
    "import xgboost as xgb\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9QOb3wEDGFy"
   },
   "source": [
    "# Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3YBq-Nu4KfNo"
   },
   "outputs": [],
   "source": [
    "data_path = './TRNcod.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mTti3fRBrMx5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "34DWy_XWrl4W",
    "outputId": "1b8a7a61-84ce-44ea-b449-885b664484a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_7</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX  UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  ...  \\\n",
       "0      0     1     1     1     0     0     0     0  0.135098       1  ...   \n",
       "1      1     1     0     1     0     0     1     0  0.273504       1  ...   \n",
       "2      2     1     0     1     0     0     1     0  0.281910       0  ...   \n",
       "3      3     1     1     1     0     0     0     0  0.225741       0  ...   \n",
       "4      4     1     1     0     0     0     1     0  0.480403       0  ...   \n",
       "\n",
       "   CEP4_7  CEP4_8  CEP4_9  CEP4_10  CEP4_11  CEP4_12  CEP4_13  CEP4_14  \\\n",
       "0       0       0       1        1        0        1        1        1   \n",
       "1       0       1       0        1        1        0        0        0   \n",
       "2       1       1       0        0        0        0        1        0   \n",
       "3       1       1       0        1        1        0        1        0   \n",
       "4       1       1       1        0        0        1        0        1   \n",
       "\n",
       "   IND_BOM_1_1  IND_BOM_1_2  \n",
       "0            0            1  \n",
       "1            1            0  \n",
       "2            1            0  \n",
       "3            1            0  \n",
       "4            1            0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['INDEX'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "147wgrxQ_eCX"
   },
   "source": [
    "#### Combinando classes em uma única coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Pn9epHSQuxrG"
   },
   "outputs": [],
   "source": [
    "def label_class (row):\n",
    "   if row['IND_BOM_1_1'] == 1 and row['IND_BOM_1_2'] == 1:\n",
    "      return 2\n",
    "   if row['IND_BOM_1_1'] == 1:\n",
    "      return 0\n",
    "   if row['IND_BOM_1_2'] == 1:\n",
    "      return 1\n",
    "   return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_yoSjoMX4W57"
   },
   "outputs": [],
   "source": [
    "df['class'] = df.apply (lambda row: label_class(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "dNlLOAJJ4bYk",
    "outputId": "a3585d0e-ed05-4955-d690-537bacb7f179"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0     1     1     1     0     0     0     0  0.135098       1   \n",
       "1     1     0     1     0     0     1     0  0.273504       1   \n",
       "2     1     0     1     0     0     1     0  0.281910       0   \n",
       "3     1     1     1     0     0     0     0  0.225741       0   \n",
       "4     1     1     0     0     0     1     0  0.480403       0   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "0                        0.222222  ...       0       1        1        0   \n",
       "1                        0.111111  ...       1       0        1        1   \n",
       "2                        1.000000  ...       1       0        0        0   \n",
       "3                        0.111111  ...       1       0        1        1   \n",
       "4                        0.111111  ...       1       1        0        0   \n",
       "\n",
       "   CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  class  \n",
       "0        1        1        1            0            1      1  \n",
       "1        0        0        0            1            0      0  \n",
       "2        0        1        0            1            0      0  \n",
       "3        0        1        0            1            0      0  \n",
       "4        1        0        1            1            0      0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4R6NcieU4fVQ",
    "outputId": "dda4136c-2c6f-47e2-a590-40507fc0916a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classe 0: 255098\n",
      "classe 1: 134098\n",
      "classe desconhecida: 0\n"
     ]
    }
   ],
   "source": [
    "print('classe 0:', len(df[df['class'] == 0]))\n",
    "print('classe 1:', len(df[df['class'] == 1]))\n",
    "print('classe desconhecida:', len(df[df['class'] > 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particionamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionamento dos dados - 1ª Etapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_class_0 = df[df['class'] == 0]\n",
    "x_class_1 = df[df['class'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273504</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281910</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480403</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219323</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "1     1     0     1     0     0     1     0  0.273504       1   \n",
       "2     1     0     1     0     0     1     0  0.281910       0   \n",
       "3     1     1     1     0     0     0     0  0.225741       0   \n",
       "4     1     1     0     0     0     1     0  0.480403       0   \n",
       "5     0     1     1     0     0     0     1  0.219323       0   \n",
       "\n",
       "   NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "1                        0.111111  ...       1       0        1        1   \n",
       "2                        1.000000  ...       1       0        0        0   \n",
       "3                        0.111111  ...       1       0        1        1   \n",
       "4                        0.111111  ...       1       1        0        0   \n",
       "5                        0.111111  ...       1       1        0        1   \n",
       "\n",
       "   CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  class  \n",
       "1        0        0        0            1            0      0  \n",
       "2        0        1        0            1            0      0  \n",
       "3        0        1        0            1            0      0  \n",
       "4        1        0        1            1            0      0  \n",
       "5        0        0        1            1            0      0  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_class_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UF_1</th>\n",
       "      <th>UF_2</th>\n",
       "      <th>UF_3</th>\n",
       "      <th>UF_4</th>\n",
       "      <th>UF_5</th>\n",
       "      <th>UF_6</th>\n",
       "      <th>UF_7</th>\n",
       "      <th>IDADE</th>\n",
       "      <th>SEXO_1</th>\n",
       "      <th>NIVEL_RELACIONAMENTO_CREDITO01</th>\n",
       "      <th>...</th>\n",
       "      <th>CEP4_8</th>\n",
       "      <th>CEP4_9</th>\n",
       "      <th>CEP4_10</th>\n",
       "      <th>CEP4_11</th>\n",
       "      <th>CEP4_12</th>\n",
       "      <th>CEP4_13</th>\n",
       "      <th>CEP4_14</th>\n",
       "      <th>IND_BOM_1_1</th>\n",
       "      <th>IND_BOM_1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135098</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654703</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.398961</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142254</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    UF_1  UF_2  UF_3  UF_4  UF_5  UF_6  UF_7     IDADE  SEXO_1  \\\n",
       "0      1     1     1     0     0     0     0  0.135098       1   \n",
       "10     1     0     1     1     0     0     0  0.654703       0   \n",
       "11     1     1     1     0     0     0     0  0.097444       1   \n",
       "12     1     0     1     0     1     0     0  0.398961       0   \n",
       "17     1     1     1     0     0     0     0  0.142254       0   \n",
       "\n",
       "    NIVEL_RELACIONAMENTO_CREDITO01  ...  CEP4_8  CEP4_9  CEP4_10  CEP4_11  \\\n",
       "0                         0.222222  ...       0       1        1        0   \n",
       "10                        0.111111  ...       1       0        1        0   \n",
       "11                        0.111111  ...       1       0        1        0   \n",
       "12                        0.111111  ...       1       1        0        1   \n",
       "17                        0.111111  ...       0       0        1        0   \n",
       "\n",
       "    CEP4_12  CEP4_13  CEP4_14  IND_BOM_1_1  IND_BOM_1_2  class  \n",
       "0         1        1        1            0            1      1  \n",
       "10        0        0        0            0            1      1  \n",
       "11        1        0        1            0            1      1  \n",
       "12        0        0        0            0            1      1  \n",
       "17        1        0        1            0            1      1  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_class_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q5lQRWw_lr9"
   },
   "source": [
    "### Particionamento dos dados - 2ª Etapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3NInOmMP70vA"
   },
   "outputs": [],
   "source": [
    "y_class_0 = x_class_0['class'].values\n",
    "y_class_1 = x_class_1['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20hYd4oJCLNG"
   },
   "source": [
    "### Particionamento dos dados - 3ª Etapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiKN6mFZCs21"
   },
   "source": [
    "Os dados foram divididos aleatoriamente usando o método train_test_split()\n",
    "- 50% dos dados para treinamento\n",
    "- Dos 50% restantes, metade(25% do total) pra validação e o restante(25%) para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class_0, X_rem_class_0, y_train_class_0, y_rem_class_0 = train_test_split(x_class_0, y_class_0, train_size=0.5)\n",
    "X_valid_class_0, X_test_class_0, y_valid_class_0, y_test_class_0 = train_test_split(X_rem_class_0, y_rem_class_0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class_1, X_rem_class_1, y_train_class_1, y_rem_class_1 = train_test_split(x_class_1, y_class_1, train_size=0.5)\n",
    "X_valid_class_1, X_test_class_1, y_valid_class_1, y_test_class_1 = train_test_split(X_rem_class_1, y_rem_class_1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_class_0, X_train_class_1])\n",
    "y_train = np.concatenate((y_train_class_0, y_train_class_1))\n",
    "X_train = X_train.drop(['class', 'IND_BOM_1_1', 'IND_BOM_1_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = pd.concat([X_valid_class_0, X_valid_class_1])\n",
    "y_valid = np.concatenate((y_valid_class_0, y_valid_class_1))\n",
    "X_valid = X_valid.drop(['class', 'IND_BOM_1_1', 'IND_BOM_1_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test_class_0, X_test_class_1])\n",
    "y_test = np.concatenate((y_test_class_0, y_test_class_1))\n",
    "X_test = X_test.drop(['class', 'IND_BOM_1_1', 'IND_BOM_1_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYXB8xrPGsxn",
    "outputId": "ff3ec40c-36e3-4733-9e8d-ea20e47340c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de entradas para treino: 194598 194598\n",
      "Quantidade de entradas para validação: 97298 97298\n",
      "Quantidade de entradas para teste: 97300 97300\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade de entradas para treino:', len(X_train), len(y_train))\n",
    "print('Quantidade de entradas para validação:', len(X_valid), len(y_valid))\n",
    "print('Quantidade de entradas para teste:', len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgyWPQ9BGe3Q"
   },
   "source": [
    "### Oversampling - Replicar a classe minoritária para ficar do tamanho da classe majoritária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5DFkN-JbH-AC",
    "outputId": "dc766e29-8e9b-4928-f09c-209cf07c3a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade antes do over sampling\n",
      "Quantidade classe 0 treino: 127549\n",
      "Quantidade classe 1 treino: 67049\n",
      "Quantidade classe 0 valid: 63774\n",
      "Quantidade classe 1 valid: 33524\n",
      "Quantidade classe 0 test: 63775\n",
      "Quantidade classe 1 test: 33525\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade antes do over sampling')\n",
    "print('Quantidade classe 0 treino:', (y_train == 0).sum())\n",
    "print('Quantidade classe 1 treino:', (y_train == 1).sum())\n",
    "print('Quantidade classe 0 valid:', (y_valid == 0).sum())\n",
    "print('Quantidade classe 1 valid:', (y_valid == 1).sum())\n",
    "print('Quantidade classe 0 test:', (y_test == 0).sum())\n",
    "print('Quantidade classe 1 test:', (y_test == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0uainKjAHCRU"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RKABwcJjGnmp",
    "outputId": "a12c51de-5554-409c-e483-5c26d1c3edf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade classe 0 treino: 127549\n",
      "Quantidade classe 1 treino: 127549\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade classe 0 treino:', (y_train == 0).sum())\n",
    "print('Quantidade classe 1 treino:', (y_train == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1kmypf-nG-13"
   },
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_valid, y_valid = oversample.fit_resample(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EoeqqfV2G-_y",
    "outputId": "d7d7e19c-65dd-4e93-b359-649ce32e5c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade classe 0 valid: 63774\n",
      "Quantidade classe 1 valid: 63774\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade classe 0 valid:', (y_valid == 0).sum())\n",
    "print('Quantidade classe 1 valid:', (y_valid == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90TA_PmcG_SM",
    "outputId": "e000f1b9-513c-4bce-8ee6-f60f05f58eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade classe 0 test: 63775\n",
      "Quantidade classe 1 test: 33525\n"
     ]
    }
   ],
   "source": [
    "print('Quantidade classe 0 test:', (y_test == 0).sum())\n",
    "print('Quantidade classe 1 test:', (y_test == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wj8xxC5c4qDQ"
   },
   "source": [
    "# Funções auxiliares para métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas utilizadas:\n",
    "\n",
    "- Teste estatístico Kolmogorov-Smirnov (KS)\n",
    "\n",
    "- Acurácia\n",
    "\n",
    "- Recall\n",
    "\n",
    "- Precision\n",
    "\n",
    "- F1-Score\n",
    "\n",
    "- Auroc (Área sob a Curva Roc)\n",
    "\n",
    "- Matriz de confusão\n",
    "      [TP  FP]\n",
    "      [FN  TN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9agHcvcrFDIf"
   },
   "outputs": [],
   "source": [
    "### VALIDAR: Teste estatístico Kolmogorov-Smirnov -KS (principal)\n",
    "### TODO: Adiconar alguns plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TYEt721Q4t7Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import roc_curve, RocCurveDisplay\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ks_statistic(y, y_pred_scores=None):\n",
    "    if y_pred_scores is not None:\n",
    "        skplt.metrics.plot_ks_statistic(y, y_pred_scores)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "g4vvpND1-2Il"
   },
   "outputs": [],
   "source": [
    "def print_metrics(actual, pred, pred_proba):\n",
    "  print('Accuracy: {:.4f}'.format(accuracy_score(actual, pred)))\n",
    "  print('Recall: {:.4f}'.format(recall_score(actual, pred)))\n",
    "  print('Precision: {:.4f}'.format(precision_score(actual, pred)))\n",
    "  print('F1-Score: {:.4f}'.format(f1_score(actual, pred)))\n",
    "  print('ROC AUC Score: {:.4f}'.format(roc_auc_score(actual, pred_proba[:, 1])))\n",
    "  print('Matriz de confusão no conjunto de teste:')\n",
    "  print(confusion_matrix(actual, pred))\n",
    "  plot_ks_statistic(actual, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "  accuracy = accuracy_score(actual, pred)\n",
    "  recall = recall_score(actual, pred)\n",
    "  precision = precision_score(actual, pred)\n",
    "  f1 = f1_score(actual, pred)\n",
    "  return accuracy, recall, precision, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYwhyxkdEt16"
   },
   "source": [
    "### Modelo MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição dos principais parâmetros:\n",
    "\n",
    " - hidden_layer_sizes: tupla, comprimento da camada oculta. O padrão é (100,), o que significa uma única camada oculta com 100 neurônios.\n",
    "\n",
    " - activation: função de ativação para a camada oculta. Os valores possíveis são ‘identity’, ‘logistic’, ‘tanh’, ‘relu’. O padrão é ‘relu’.\n",
    "\n",
    " - learning_rate_init: a taxa de aprendizado inicial para ‘sgd’ ou ‘adam’. O padrão é 0,001. Nota: a taxa de aprendizado é sempre modificada para ‘learning_rate_init’ quando ‘learning_rate’ é definido como ‘invscaling’ ou ‘adaptive’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ª Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100), batch_size=64, activation='tanh', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.55223588\n",
      "Iteration 2, loss = 0.51511129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonat\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:709: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, batch_size=64, hidden_layer_sizes=(100, 100),\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, batch_size=64, hidden_layer_sizes=(100, 100),\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', batch_size=64, hidden_layer_sizes=(100, 100),\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mlp_pred_valid = mlp.predict(X_valid)\n",
    "y_mlp_pred_valid_proba = mlp.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7220\n",
      "Recall: 0.6399\n",
      "Precision: 0.7657\n",
      "F1-Score: 0.6972\n",
      "ROC AUC Score: 0.8006\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[51285 12489]\n",
      " [22964 40810]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_metrics(y_valid, y_mlp_pred_valid, y_mlp_pred_valid_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descrição dos principais parâmetros:\n",
    "\n",
    "- C\n",
    "  - Parâmetro de regularização. A força da regularização é inversamente proporcional a C. Deve ser estritamente positiva. A penalidade é uma penalidade de 12 ao quadrado.\n",
    "\n",
    "- kernel\n",
    "  - Especifica o tipo de kernel a ser usado no algoritmo. Se nenhum for fornecido, 'rbf' será usado. Se um callable for fornecido, ele será usado para pré-computar a matriz do kernel a partir de matrizes de dados; essa matriz deve ser uma matriz de forma\n",
    "  - Valor default: rbf\n",
    "\n",
    "- degree\n",
    "  - Grau da função kernel polinomial ('poli'). Ignorado por todos os outros kernels.\n",
    "  - Valor default: 3\n",
    "\n",
    "- gamma\n",
    "  - Coeficiente de kernel para 'rbf', 'poli' e 'sigmóide'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(gamma='auto', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# clf_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_valid_pred_svm = clf_svm.predict(X_valid)\n",
    "# y_valid_pred_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid_proba_svm = clf_svm.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Métricas da 1ª configuração do SVM:\\n')\n",
    "# print_metrics(y_valid, y_valid_pred_svm, y_valid_proba_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segundo a própria documentação do Scikit learn para dataset muito grandes é aconselhável usarmos o LinearSVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf_svm_linear = LinearSVC(random_state=0, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/29 18:47:35 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '4ef9cc0f2cab4272b1b1510c507545cf', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "2022/09/29 18:51:41 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 11s, sys: 10.2 s, total: 4min 22s\n",
      "Wall time: 4min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(random_state=0, tol=1e-05)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# clf_svm_linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid_pred_svm_linear = clf_svm_linear.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do SVM SVC Linear:\n",
      "\n",
      "Accuracy: 0.7301\n",
      "Recall: 0.6573\n",
      "Precision: 0.7692\n",
      "F1-Score: 0.7089\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[51199 12575]\n",
      " [21854 41920]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do SVM SVC Linear:\\n')\n",
    "print_metrics(y_valid, y_valid_pred_svm_linear,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_performance_metrics(y_test, y_pred_class, y_pred_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição dos parâmetros\n",
    "* base_estimator object, default=None\n",
    "    * O estimador base a partir do qual o conjunto impulsionado é construído. É necessário suporte para ponderação de amostra, bem como atributos classes_ e n_classes_ apropriados. Se Nenhum, então o estimador base é DecisionTreeClassifier inicializado com max_depth=1.\n",
    "\n",
    "* n_estimators int, default=50\n",
    "    * O número máximo de estimadores em que o reforço é encerrado. Em caso de ajuste perfeito, o processo de aprendizagem é interrompido precocemente. Os valores devem estar no intervalo [1, inf).\n",
    "\n",
    "* learning_rate float, default=1.0\n",
    "    * Peso aplicado a cada classificador em cada iteração de reforço. Uma taxa de aprendizado mais alta aumenta a contribuição de cada classificador. Há um trade-off entre os parâmetros learning_rate e n_estimators. Os valores devem estar no intervalo (0,0, inf).\n",
    "\n",
    "* algorithm {‘SAMME’, ‘SAMME.R’}, default=’SAMME.R’\n",
    "    * Se 'SAMME.R', use o algoritmo de reforço real SAMME.R. base_estimator deve suportar o cálculo de probabilidades de classe. Se 'SAMME', use o algoritmo de reforço discreto SAMME. O algoritmo SAMME.R normalmente converge mais rápido que o SAMME, alcançando um erro de teste menor com menos iterações de reforço.\n",
    "\n",
    "* random_state int, RandomState instance or None, default=None\n",
    "    * Controla a semente aleatória fornecida em cada base_estimator em cada iteração de reforço. Assim, ele só é usado quando base_estimator expõe um random_state. Passe um int para saída reproduzível em várias chamadas de função. Consulte Glossário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- n_estimators = 100\n",
    "\n",
    "- learning_rate = 1\n",
    "\n",
    "- algorithm = SAMME.R\n",
    "\n",
    "- random_state = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_adaBoost = AdaBoostClassifier(n_estimators=100, learning_rate = 1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_adaBoost = clf_adaBoost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred_adaBoost = clf_adaBoost.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_proba_adaBoost = clf_adaBoost.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Métricas da 1ª configuração do Adaboost:\\n')\n",
    "print_metrics(y_valid, y_valid_pred_adaBoost, y_valid_proba_adaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYwhyxkdEt16"
   },
   "source": [
    "### Modelo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAZM1rGKHb-7"
   },
   "source": [
    "Descrição dos parâmetros:\n",
    "\n",
    "- n_estimators\n",
    "  - O número de árvores na floresta.\n",
    "\n",
    "- criterion\n",
    "  - A função para medir a qualidade de uma divisão\n",
    "\n",
    "- max_depth\n",
    "  - A profundidade máxima da árvore.\n",
    "  - 'None' significa que os nós são expandidos até que todas as folhas sejam puras(se o nó possui prediz apenas 1 classe) ou até que todas as folhas contenham menos de min_samples_split amostras.\n",
    "\n",
    "- min_samples_split\n",
    "  - O número mínimo de amostras necessárias para dividir um nó.\n",
    "\n",
    "- min_samples_leaf\n",
    "  - O número mínimo de amostrar necessárias para ser um nó folha.\n",
    "\n",
    "- max_features\n",
    "  - O número de features a serem considerados ao procurar a melhor divisão. Por exemplo, caso a função seja 'sqrt', a cada divisão ele tenta buscar uma condição que possua sqrt(n_node) entradas. \n",
    "\n",
    "- max_leaf_nodes\n",
    "  - O número max de nós folha. \n",
    "  - 'None' significa então pode haver um número ilimitado de nós folha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "sHmEuyCIEv7O"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dNd5Uvg4fjC"
   },
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HDyP542CdtN"
   },
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- n_estimators = 100\n",
    "\n",
    "- criterion = 'gini'\n",
    "\n",
    "- max_depth = None \n",
    "\n",
    "- min_samples_split = 2\n",
    "\n",
    "- min_samples_leaf = 1\n",
    "\n",
    "- max_features = 'sqrt'\n",
    "\n",
    "- max_leaf_nodes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "kIs_MMjkhsU5"
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bluXpSrShs9A",
    "outputId": "cfb3b8d7-8054-43b4-9535-50c2da3d924a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/04 22:04:14 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '008cb0e73d97481d8689d932af7a008d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2022/10/04 22:04:53 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 50s, sys: 12.4 s, total: 11min 2s\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history_rf = clf_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_rf = clf_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba_rf = clf_rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Z1S6I96qLQ"
   },
   "source": [
    "##### 1a Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6699\n",
      "Recall: 0.3792\n",
      "Precision: 0.5292\n",
      "F1-Score: 0.4418\n",
      "ROC AUC Score: 0.6796\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[52467 11308]\n",
      " [20812 12713]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_metrics(y_test, y_test_pred_rf, y_test_proba_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVdid7yEMS8"
   },
   "source": [
    "#### 2ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7nArA2JE1Zk"
   },
   "source": [
    "Para a segunda configuração vamos criar um estudo de caso usando o optuna, variando alguns hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-X1R61biD1G4"
   },
   "outputs": [],
   "source": [
    "def random_forest(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 100),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n",
    "    }\n",
    "    # Create the model\n",
    "    rnd_forest = RandomForestClassifier(\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        min_samples_split=params[\"min_samples_split\"],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rnd_forest.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_valid = rnd_forest.predict(X_valid)\n",
    "    y_pred_proba = rnd_forest.predict_proba(X_valid)\n",
    "\n",
    "    (accuracy, recall, precision, f1) = eval_metrics(y_valid, y_pred_valid)\n",
    "\n",
    "    gc.collect()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-29 18:59:27,225]\u001b[0m A new study created in memory with name: no-name-60e35998-c952-4007-a110-39236862f3e1\u001b[0m\n",
      "2022/09/29 18:59:57 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:00:01,534]\u001b[0m Trial 0 finished with value: 0.7403487314579609 and parameters: {'n_estimators': 126, 'max_depth': 18, 'min_samples_split': 75}. Best is trial 0 with value: 0.7403487314579609.\u001b[0m\n",
      "2022/09/29 19:00:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:00:43,070]\u001b[0m Trial 1 finished with value: 0.7414698780067112 and parameters: {'n_estimators': 121, 'max_depth': 57, 'min_samples_split': 25}. Best is trial 1 with value: 0.7414698780067112.\u001b[0m\n",
      "2022/09/29 19:01:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:01:08,486]\u001b[0m Trial 2 finished with value: 0.7409994668673754 and parameters: {'n_estimators': 66, 'max_depth': 89, 'min_samples_split': 44}. Best is trial 1 with value: 0.7414698780067112.\u001b[0m\n",
      "2022/09/29 19:02:04 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:02:09,412]\u001b[0m Trial 3 finished with value: 0.7439552168595353 and parameters: {'n_estimators': 236, 'max_depth': 52, 'min_samples_split': 97}. Best is trial 3 with value: 0.7439552168595353.\u001b[0m\n",
      "2022/09/29 19:03:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:03:46,312]\u001b[0m Trial 4 finished with value: 0.7436808103615894 and parameters: {'n_estimators': 347, 'max_depth': 32, 'min_samples_split': 25}. Best is trial 3 with value: 0.7439552168595353.\u001b[0m\n",
      "2022/09/29 19:04:43 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:04:49,186]\u001b[0m Trial 5 finished with value: 0.744950920437796 and parameters: {'n_estimators': 236, 'max_depth': 51, 'min_samples_split': 57}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n",
      "2022/09/29 19:06:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:06:21,950]\u001b[0m Trial 6 finished with value: 0.7434377646062659 and parameters: {'n_estimators': 331, 'max_depth': 42, 'min_samples_split': 21}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n",
      "2022/09/29 19:06:42 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-29 19:06:46,148]\u001b[0m Trial 7 finished with value: 0.7419246087747358 and parameters: {'n_estimators': 72, 'max_depth': 62, 'min_samples_split': 85}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n",
      "2022/09/29 19:07:37 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:07:42,908]\u001b[0m Trial 8 finished with value: 0.7439944177878132 and parameters: {'n_estimators': 213, 'max_depth': 47, 'min_samples_split': 60}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n",
      "2022/09/29 19:08:46 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/home/ubuntu/.local/lib/python3.7/site-packages/mlflow/models/signature.py:129: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "\u001b[32m[I 2022-09-29 19:08:52,312]\u001b[0m Trial 9 finished with value: 0.7443237055853482 and parameters: {'n_estimators': 262, 'max_depth': 75, 'min_samples_split': 49}. Best is trial 5 with value: 0.744950920437796.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rf = optuna.create_study(direction=\"maximize\")\n",
    "rf.optimize(random_forest, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYwhyxkdEt16"
   },
   "source": [
    "### Modelo Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAZM1rGKHb-7"
   },
   "source": [
    "Descrição dos parâmetros:\n",
    "\n",
    "- loss\n",
    "  - Possíveis valores: ‘log_loss’, ‘exponential’\n",
    "  - default=’log_loss’\n",
    "  - A função de perda a ser otimizada. \n",
    "    - 'log_loss' refere-se ao desvio binomial e multinomial, o mesmo usado na regressão logística. É uma boa escolha para classificação com saídas probabilísticas. \n",
    "    - 'exponencial', o aumento de gradiente recupera o algoritmo AdaBoost.\n",
    "\n",
    "- learning_rate\n",
    "  - Possíveis valores: intervalo (0,0, inf)\n",
    "  - default=0.1\n",
    "  - A taxa de aprendizado reduz a contribuição de cada árvore por learning_rate. Há um trade-off entre learning_rate e n_estimators. \n",
    "\n",
    "- n_estimators\n",
    "  - Os valores devem estar no intervalo [1, inf).\n",
    "  - default=100\n",
    "  - O número de estágios de reforço a serem executados. \n",
    "  - **O aumento de gradiente é bastante robusto ao over-fitting, portanto, um número grande geralmente resulta em melhor desempenho.\n",
    "\n",
    "- subsample\n",
    "  - Os valores devem estar no intervalo (0,0, 1,0].\n",
    "  - default=1.0\n",
    "  - A fração de amostras a ser usada para ajustar os 'individual base learners'. \n",
    "  - Se menor que 1,0, isso resulta em aumento de gradiente estocástico. subamostra interage com o parâmetro n_estimators. \n",
    "    - **Escolher subamostra < 1,0 leva a uma redução da variância e a um aumento no viés.\n",
    "\n",
    "- criterion\n",
    "  - Possíveis valores: {‘friedman_mse’, ‘squared_error’, ‘mse’}\n",
    "  - default=’friedman_mse’\n",
    "  - A função para medir a qualidade de uma divisão. \n",
    "  - Os critérios suportados são:\n",
    "    - ‘friedman_mse’ para o erro quadrático médio com pontuação de melhoria por Friedman, \n",
    "    - ‘squared_error’ para erro quadrático médio. \n",
    "  - **O valor padrão de ‘friedman_mse’ geralmente é o melhor, pois pode fornecer uma melhor aproximação em alguns casos.\n",
    "\n",
    "- min_samples_split\n",
    "  - Possíveis valores: int or float\n",
    "  - default=2\n",
    "  - Se int, os valores devem estar no intervalo [1, inf).\n",
    "  - Se float, os valores devem estar no intervalo (0.0, 1.0] e min_samples_leaf será ceil(min_samples_leaf * n_samples).\n",
    "\n",
    "- min_samples_leaf\n",
    "  - Possíveis valores: int or float\n",
    "  - default=1\n",
    "  - Isso pode ter o efeito de suavizar o modelo, especialmente na regressão.\n",
    "\n",
    "- min_weight_fraction_leaf\n",
    "  - Os valores devem estar no intervalo [0,0, 0,5].\n",
    "  - default=0.0(As amostras têm peso igual)\n",
    "  - A fração ponderada mínima da soma total de pesos (de todas as amostras de entrada) necessária para estar em um nó folha. \n",
    "\n",
    "- max_depth\n",
    "  - Os valores devem estar no intervalo [1, inf).\n",
    "  - default=3\n",
    "  - Ajuste este parâmetro para melhorar o desempenho; \n",
    "    - O melhor valor depende da interação das variáveis de entrada.\n",
    "\n",
    "- min_impurity_decrease\n",
    "  - Os valores devem estar no intervalo [0,0, inf).\n",
    "  - default=0.0\n",
    "  - Um nó será dividido se esta divisão induzir uma diminuição da impureza maior ou igual a este valor.\n",
    "\n",
    "- init\n",
    "  - Possíveis valores: estimator or ‘zero’\n",
    "  - default=None(é usado um DummyEstimator)\n",
    "  - Um objeto estimador que é usado para calcular as previsões iniciais. \n",
    "  - init tem que fornecer fit e predict_proba. \n",
    "  - Se 'zero', as previsões brutas iniciais são definidas como zero. \n",
    "\n",
    "- max_features\n",
    "  - Possíveis valores: {‘auto’, ‘sqrt’, ‘log2’}, int or float\n",
    "    - Se int, valores devem estar no intervalo  [1, inf).\n",
    "    - Se float, valores devem estar no intervalo  (0.0, 1.0] and the features considered at each split will be max(1, int(max_features * n_features_in_)).\n",
    "    - Se f = ‘auto’, ‘sqrt’, ‘log2’, então max_features = f(n_features).\n",
    "    - Se None, então max_features = n_features.\n",
    "  - default=None\n",
    "  - O número de features para considerar quando buscar pelo melhor split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "sHmEuyCIEv7O"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dNd5Uvg4fjC"
   },
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HDyP542CdtN"
   },
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- loss\n",
    "  - default=’log_loss’\n",
    "\n",
    "- learning_rate\n",
    "  - default=0.1\n",
    "\n",
    "- n_estimators\n",
    "  - default=100\n",
    "\n",
    "- subsample\n",
    "  - default=1.0\n",
    "\n",
    "- criterion\n",
    "  - default=’friedman_mse’\n",
    "\n",
    "- min_samples_split\n",
    "  - default=2\n",
    "\n",
    "- min_samples_leaf\n",
    "  - default=1\n",
    "\n",
    "- min_weight_fraction_leaf\n",
    "  - default=0.0(As amostras têm peso igual)\n",
    "\n",
    "- max_depth\n",
    "  - default=3\n",
    "\n",
    "- min_impurity_decrease\n",
    "  - default=0.0\n",
    "\n",
    "- init\n",
    "  - default=None(é usado um DummyEstimator)\n",
    "\n",
    "- max_features\n",
    "  - default=None(então max_features = n_features.)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "kIs_MMjkhsU5"
   },
   "outputs": [],
   "source": [
    "clf_gb = xgb.XGBClassifier(random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bluXpSrShs9A",
    "outputId": "cfb3b8d7-8054-43b4-9535-50c2da3d924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 46s, sys: 672 ms, total: 15min 47s\n",
      "Wall time: 40.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=27,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "yb7fjHhZhtPs"
   },
   "outputs": [],
   "source": [
    "y_pred_gb = clf_gb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "HGTVUGv0CJ07"
   },
   "outputs": [],
   "source": [
    "y_proba_gb = clf_gb.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Z1S6I96qLQ"
   },
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0smRYcg6rsc",
    "outputId": "d80c2163-462c-4353-d3ef-660befa28a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do Random Forest:\n",
      "\n",
      "Accuracy: 0.7570\n",
      "Recall: 0.6686\n",
      "Precision: 0.8121\n",
      "F1-Score: 0.7334\n",
      "ROC AUC Score: 0.8412\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[53909  9865]\n",
      " [21135 42639]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do Random Forest:\\n')\n",
    "print_metrics(y_valid, y_pred_gb, y_proba_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVdid7yEMS8"
   },
   "source": [
    "#### 2ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7nArA2JE1Zk"
   },
   "source": [
    "Para a segunda configuração alteramos os seguintes parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "-X1R61biD1G4"
   },
   "outputs": [],
   "source": [
    "def gradient_boosting(trial):\n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate ', 0.0001, 0.1, step=0.005),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 100),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300, step=10)\n",
    "    }\n",
    "    # 'min_samples_split': trial.suggest_int('min_samples_split', 2, 100),\n",
    "    # Create the model\n",
    "    gb_clf_trial = xgb.XGBClassifier(\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        max_depth=params[\"max_depth\"],\n",
    "        n_estimators=params[\"n_estimators\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    print(\"Training model with params\", params)\n",
    "    gb_clf_trial.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_valid = gb_clf_trial.predict(X_valid)\n",
    "    y_pred_proba = gb_clf_trial.predict_proba(X_valid)\n",
    "\n",
    "    (accuracy, recall, precision, f1) = eval_metrics(y_valid, y_pred_valid)\n",
    "\n",
    "    gc.collect()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 03:41:51,757]\u001b[0m A new study created in memory with name: no-name-6d9d3dc5-6165-4317-b52f-c71c0067ae07\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0751, 'max_depth': 5, 'n_estimators': 190}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 03:42:56,244]\u001b[0m Trial 0 finished with value: 0.7599570357826073 and parameters: {'learning_rate ': 0.0751, 'max_depth': 5, 'n_estimators': 190}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.08510000000000001, 'max_depth': 88, 'n_estimators': 110}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 03:49:04,054]\u001b[0m Trial 1 finished with value: 0.7464248753410481 and parameters: {'learning_rate ': 0.08510000000000001, 'max_depth': 88, 'n_estimators': 110}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0801, 'max_depth': 36, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:02:31,447]\u001b[0m Trial 2 finished with value: 0.7507761783799041 and parameters: {'learning_rate ': 0.0801, 'max_depth': 36, 'n_estimators': 300}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0951, 'max_depth': 45, 'n_estimators': 140}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:09:48,697]\u001b[0m Trial 3 finished with value: 0.748447643240192 and parameters: {'learning_rate ': 0.0951, 'max_depth': 45, 'n_estimators': 140}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0101, 'max_depth': 81, 'n_estimators': 120}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:18:12,463]\u001b[0m Trial 4 finished with value: 0.7250603694295481 and parameters: {'learning_rate ': 0.0101, 'max_depth': 81, 'n_estimators': 120}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0601, 'max_depth': 17, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:21:01,868]\u001b[0m Trial 5 finished with value: 0.7539906544986985 and parameters: {'learning_rate ': 0.0601, 'max_depth': 17, 'n_estimators': 100}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0951, 'max_depth': 75, 'n_estimators': 220}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:31:41,724]\u001b[0m Trial 6 finished with value: 0.7493257440336187 and parameters: {'learning_rate ': 0.0951, 'max_depth': 75, 'n_estimators': 220}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.015099999999999999, 'max_depth': 94, 'n_estimators': 300}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:50:08,844]\u001b[0m Trial 7 finished with value: 0.7448411578386176 and parameters: {'learning_rate ': 0.015099999999999999, 'max_depth': 94, 'n_estimators': 300}. Best is trial 0 with value: 0.7599570357826073.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.0751, 'max_depth': 7, 'n_estimators': 270}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 04:52:16,947]\u001b[0m Trial 8 finished with value: 0.7615407532850378 and parameters: {'learning_rate ': 0.0751, 'max_depth': 7, 'n_estimators': 270}. Best is trial 8 with value: 0.7615407532850378.\u001b[0m\n",
      "/home/ubuntu/.local/lib/python3.7/site-packages/optuna/distributions.py:671: UserWarning: The distribution is specified by [0.0001, 0.1] and step=0.005, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.0951].\n",
      "  low=low, old_high=old_high, high=high, step=step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with params {'learning_rate': 0.015099999999999999, 'max_depth': 46, 'n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-30 05:05:07,544]\u001b[0m Trial 9 finished with value: 0.7403408912723053 and parameters: {'learning_rate ': 0.015099999999999999, 'max_depth': 46, 'n_estimators': 200}. Best is trial 8 with value: 0.7615407532850378.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "gb = optuna.create_study(direction=\"maximize\")\n",
    "gb.optimize(gradient_boosting, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anexos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAZM1rGKHb-7"
   },
   "source": [
    "Descrição dos parâmetros:\n",
    "\n",
    "- n_estimators\n",
    "  - O número de árvores na floresta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/ubuntu/.local/lib/python3.7/site-packages (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/anaconda/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (65.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/anaconda/lib/python3.7/site-packages (from tensorflow) (1.11.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (3.19.5)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/anaconda/lib/python3.7/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/anaconda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.33.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/anaconda/lib/python3.7/site-packages (from packaging->tensorflow) (2.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ubuntu/.local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/.local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anaconda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2019.3.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ubuntu/.local/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ubuntu/.local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ubuntu/.local/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/.local/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "sHmEuyCIEv7O"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dNd5Uvg4fjC"
   },
   "source": [
    "#### 1ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HDyP542CdtN"
   },
   "source": [
    "A primeira configuração é utilizada com os parâmetros padrões do Sklearn.\n",
    "\n",
    "Segue abaixo a lista dos principais hiperparâmetros:\n",
    "\n",
    "- n_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sklearn_compatible_model():\n",
    "    input_dim = X_train.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, activation='tanh', input_dim=input_dim))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "kIs_MMjkhsU5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "clf_mlp = KerasClassifier(build_fn=create_sklearn_compatible_model, \n",
    "                          batch_size=64, epochs=100,\n",
    "                          verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bluXpSrShs9A",
    "outputId": "cfb3b8d7-8054-43b4-9535-50c2da3d924a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 39s, sys: 4min 4s, total: 22min 43s\n",
      "Wall time: 9min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73e08bccf8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "yb7fjHhZhtPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3986 [==============================] - 4s 969us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_mlp = clf_mlp.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "HGTVUGv0CJ07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986/3986 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_proba_mlp = clf_mlp.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Z1S6I96qLQ"
   },
   "source": [
    "##### Análise de Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0smRYcg6rsc",
    "outputId": "d80c2163-462c-4353-d3ef-660befa28a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas da 1ª configuração do Random Forest:\n",
      "\n",
      "Accuracy: 0.7295\n",
      "Recall: 0.6847\n",
      "Precision: 0.7521\n",
      "F1-Score: 0.7168\n",
      "ROC AUC Score: 0.8149\n",
      "Matriz de confusão no conjunto de teste:\n",
      "[[49379 14395]\n",
      " [20110 43664]]\n"
     ]
    }
   ],
   "source": [
    "print('Métricas da 1ª configuração do Random Forest:\\n')\n",
    "print_metrics(y_valid, y_pred_mlp, y_proba_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pVdid7yEMS8"
   },
   "source": [
    "#### 2ª Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7nArA2JE1Zk"
   },
   "source": [
    "Para a segunda configuração alteramos os seguintes parâmetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X1R61biD1G4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest usando K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não teremos mais isso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "scores = []\n",
    "# cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# for train_index, test_index in cv.split(X_train):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index, \"LEN:\", X_train.loc[255096:255097])\n",
    "#     X_train2, X_test2, y_train2, y_test2 = X_train[train_index], X_train[test_index], y_train[train_index], y_train[test_index]\n",
    "#     clf_rf.fit(X_train2, y_train2)\n",
    "#     scores.append(clf_rf.score(X_test2, y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76057531, 0.76244517, 0.76138395])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(clf_rf, X_train, y_train, cv=kfold, scoring='accuracy')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a68ab044c6ea367198d7b58f0f8352272d5267d2d2c131306c104f6e9ede3d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
